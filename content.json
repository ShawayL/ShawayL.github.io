{"posts":[{"title":"c++中的const和constexpr","text":"const的基础用法不多赘述，记录一下其他的点 1.const变量的跨文件使用const 对象被设定为仅在文件内有效。当多个文件中出现了同名的 const 变量时，其实等同于在不同文件中分别定义了独立的变量。 例如有以下三个文件 test1.h 12345int getRandom();void fun();const int r = getRandom(); test1.cpp 12345678910111213#include &lt;iostream&gt;#include &quot;test1.h&quot;int getRandom(){ /*生成随机数并返回*/}void fun(){ std::cout&lt;&lt;r&lt;&lt;std::endl;} main.cpp 12345678910#include &lt;iostream&gt;#include &quot;test1.h&quot;int main(){ std::cout&lt;&lt;r&lt;&lt;std::endl; fun(); return 0;} 其运行结果输出的两个数字是不一样的。 如果想要多个文件共享同一个const变量，我们可以把const变量的声明和定义分开，并且在声明的时候加上extern关键字，例如 test1.h 12345int getRandom();void fun();extern const int r; test1.cpp 123456789101112131415#include &lt;iostream&gt;#include &quot;test1.h&quot;const int r = getRandom();int getRandom(){ /*生成随机数并返回*/}void fun(){ std::cout&lt;&lt;r&lt;&lt;std::endl;} main.cpp 12345678910#include &lt;iostream&gt;#include &quot;test1.h&quot;int main(){ std::cout&lt;&lt;r&lt;&lt;std::endl; fun(); return 0;} 2.顶层/底层const顶层const：意思是指针/变量本身是个常量 底层const：意思是指针所指向的对象是个常量 1234int i = 0;const int* p1 = &amp;i; //底层const,也可以写成int const* p1 = &amp;i;int* const p2 = &amp;i; //顶层constconst int ci = 42; //顶层const 3.constexprconstexpr指的是值不会改变并且在编译阶段就能计算出来结果的表达式，它和const的区别是const强调不可修改，constexpr强调在编译器就可以计算出来结果并且不可改变。 代码如下： 1234int main() { const int val = 1 + 2; return 0;} 上面的这份代码编译后会把3直接赋值给val，可以看的出来3是在编译期间求出来的值 12345678int Add(const int a, const int b) { return a + b;}int main() { const int val = Add(1, 2); return 0;} 这份代码在编译期间就没有进行求值，而是运行期间进行了求值 1234int main() { constexpr int val = 1 + 2; return 0;} 这份代码在编译后的结果和第一份代码的编译结果一摸一样，说明constexpr和const一样可以在编译期间求值 12345678constexpr int Add(const int a, const int b) { return a + b;}int main() { const int val = Add(1, 2); return 0;} 这份代码在第二份的代码上做了优化，用constexpr去修饰函数，使其可以在编译期间求值 12345678910constexpr int Add(const int a, const int b) { return a + b;}int main() { const int val = Add(1, 2); int val1 = 3; int val2 = Add(val, val1); return 0;} 在这份代码中val在编译期间求值，而val2在运行期间求值，因为其引入了非const变量val1 通过本示例，可以看出，将函数声明为constexpr可以提示效率，让编译器来决定是在编译阶段还是运行阶段来进行求值","link":"/C_C++/cpp%E4%B8%AD%E7%9A%84const%E5%92%8Cconstexpr/"},{"title":"c++右值引用和std::move","text":"什么是左值、右值左值可以取地址、位于等号左边；而右值没法取地址，位于等号右边。 什么是左值引用、右值引用左值引用左值引用就是指向左值的引用，左值引用不能指向右值 123int a = 0;int&amp; b = a; //b是一个左值引用int&amp; c = 6; //编译错误，因为6是一个右值，左值引用不能绑定在右值上 左值引用不能指向右值，因为左值引用允许修改被引用变量的值，但是右值没有地址，无法修改 const左值引用可以指向右值，因为const左值引用无法修改指向对象的值，所以STL许多函数的参数都是const type&amp; 右值引用右值引用就是可以指向右值的引用，右值引用不能指向左值 1234int&amp;&amp; a = 6;//a是一个右值引用int b = 5;int&amp;&amp; c = b;//错误，b是一个左值a = 7;//右值引用允许修改右值 std::move函数std::move函数是将一个左值转换成右值，函数本身和移动没有关系，仅仅是把左值转换成了右值 123int a = 6;int&amp; b = a;int&amp;&amp; c = std::move(a);//通过std::move把一个左值转换成了右值 因为std::move的作用仅仅是转换，所以性能上不会有任何提升 右值引用本身是左值还是右值先说结论：被声明出来的，有名称的右值引用其本身就是左值，因为其有地址，其他的是右值。也可以说作为函数返回值的 &amp;&amp; 是右值，直接声明出来的 &amp;&amp; 是左值。 123456789101112131415161718192021void fun(int&amp;&amp; n){ n = 1;}int main(){ int a = 5; int&amp; b = a; int&amp;&amp; c = std::move(a); fun(a);//错误，a是一个左值 fun(b);//错误，b是一个左值引用 fun(c);//错误，c本身是一个左值 fun(std::move(a));//正确 fun(std::move(b));//正确 fun(std::move(c));//正确 fun(6);//正确} std::move函数的应用场景std::move函数是将一个左值转换成右值，仅仅有转换功能，函数本身和移动没有关系，因此std::move函数本身并不能提高性能，需要配合移动构造函数或移动赋值函数来实现移动语义从而避免产生深拷贝来提升性能。 因此std::move可以在对象需要拷贝且被拷贝者之后不再被需要的这种情况下提升性能 例如有如下类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869class Obj{public: //默认构造函数 Obj() { mem = nullptr; len = 0; } //构造函数 Obj(size_t len) { this-&gt;len = len; mem = (char*)(malloc(len)); memset(mem, 1, len); } //析构函数 ~Obj() { if(mem) free(mem); } //拷贝构造函数 Obj(const Obj&amp; other) { len = other.len; mem = nullptr; if(len &gt; 0) { mem = (char*)(malloc(len)); memcpy(mem, other.mem, other.len); } } //拷贝赋值函数 Obj&amp; operator =(const Obj&amp; other) { if(mem) free(mem); len = other.len; mem = nullptr; if(len &gt; 0) { mem = (char*)(malloc(len)); memcpy(mem, other.mem, other.len); } return *this; } //移动构造函数 Obj(Obj&amp;&amp; other) { len = other.len; mem = other.mem; other.len = 0; other.mem = nullptr; } //移动赋值函数 Obj&amp; operator =(Obj&amp;&amp; other) { len = other.len; mem = other.mem; other.len = 0; other.mem = nullptr; return *this; }private: char* mem; size_t len;}; 类中维护了一段内存，如果调用拷贝构造和拷贝赋值就会重新申请内存并写入数据，如果调用移动构造和移动赋值就仅会把mem的所有权给移动一下。相比之下移动构造和移动赋值函数的性能是比拷贝构造和拷贝复制的性能要高的。但是有一点要记住就是被移动的对象再移动完之后内部的资源都会被清空。 例如有以下调用函数 123456789101112131415161718192021222324252627int main(){ int allCount = 1000000; size_t perSize = 10; std::vector&lt;Obj&gt; v; v.reserve(allCount); v.resize(0); auto start = std::clock(); for(size_t i = 0; i &lt; allCount; i++) { Obj obj(perSize); v.push_back(obj); } printf(&quot;push_back time:%lfs\\n&quot;, ((double)(std::clock()-start))/CLOCKS_PER_SEC); v.resize(0); start = std::clock(); for(size_t i = 0; i &lt; allCount; i++) { Obj obj(perSize); v.push_back(std::move(obj)); } printf(&quot;move push_back time:%lfs\\n&quot;, ((double)(std::clock()-start))/CLOCKS_PER_SEC); return 0; } 第一个循环用了普通的push_back会调用拷贝构造函数，第二个循环先用std::move把左值转换成右值然后再调用push_back函数就会调用移动构造函数，但是每个循环内部的obj在push_back后其中的数据也被清空了。经过实现第二个循环的效率比第一个循环要高。 上述代码在Compiler Explorer的运行: 还有一些对象是只允许移动不允许拷贝的，比如unique_ptr，这种对象只允许移动内部资源所有权 完美转发std::forwardstd::forward与std::move一样也是类型转换，但是std::move只能转出来右值，而std::forward可以转出来左值或右值 std::forward(u)有两个参数：T与 u。 1. 当T为左值引用类型时，u将被转换为T类型的左值； 2. 否则u将被转换为T类型右值。 12345678910111213141516171819202122232425void fun1(int&amp;&amp; n){ n = 2;}void fun2(int&amp; n){ n = 2;}int main(){ int n = 0; int&amp;&amp; nr = std::move(n); fun1(nr);//错误 nr是一个左值 fun1(std::move(nr));//正确 转换成了右值 fun1(std::forward&lt;int&gt;(nr));//正确 转换成了右值 fun2(nr);//正确 nr是一个左值 fun2(std::move(nr));//错误 左值引用无法绑定到右值上 fun2(std::forward&lt;int&amp;&gt;(nr));//正确 转换成了左值引用 return 0;}","link":"/C_C++/cpp%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8%E5%92%8Cstd-move/"},{"title":"c++的RAII技术","text":"RAII，全称资源获取即初始化（英语：Resource Acquisition Is Initialization），它是在一些面向对象语言中的一种惯用法。RAII源于C++，在Java，C#，D，Ada，Vala和Rust中也有应用。1984-1989年期间，比雅尼·斯特劳斯特鲁普和安德鲁·柯尼希在设计C++异常时，为解决资源管理时的异常安全性而使用了该用法[1]，后来比雅尼·斯特劳斯特鲁普将其称为RAII[2]。 RAII就自己的理解来说就是把两个成对的操作绑定到一个对象的生命周期上，对象构造时执行操作1，对象析构时执行操作2，这样一来不管是正常退出还是异常退出都能保证两个成对的操作都会被执行从而让代码更加安全。 c++中的lock_guard就使用了RAII: 1234567891011template &lt;class Mutex&gt; class lock_guard {private: Mutex&amp; mutex_;public: lock_guard(Mutex&amp; mutex) : mutex_(mutex) { mutex_.lock(); } ~lock_guard() { mutex_.unlock(); } lock_guard(lock_guard const&amp;) = delete; lock_guard&amp; operator=(lock_guard const&amp;) = delete;}; 使用: 123456789101112extern void unsafe_code(); // 可能抛出异常using std::mutex;using std::lock_guard;mutex g_mutex;void access_critical_section(){ lock_guard&lt;mutex&gt; lock(g_mutex); unsafe_code();}","link":"/C_C++/cpp%E7%9A%84RAII%E6%8A%80%E6%9C%AF/"},{"title":"关于内存对齐","text":"要理解内存对齐，首先明白一个概念，在现代计算机体系中，CPU从内存中拿数据，CPU与内存通过总线连接，进行数据读写。在x86体系下，总线位宽是32位，这也是所有指针类型都占用4个字节的原因。既然总线位宽是32位，那就意味着CPU一次可以从内存拿到连续4个字节的数据。这样，将数据按照相隔4字节进行存放，存取的效率是最高的，相邻距离在4字节以内，存取效率反而会降低了。64位系统与之同理，只不过64位系统一次可读写的值是8字节。 为了提高存取的效率，编译器在存放结构体的时候，会默认对结构体的成员进行内存对齐，也就是在结构体的各个成员后面填充空字节，使填充后的结构体大小满足对齐要求，从面更方便CPU读写，对齐的规则如下： 只按char、short、int、float、double、指针等“原子类型”对齐，结构体嵌套时，需要将子结构体展开成原子类型。 char对齐值为1，short对齐值为2，int、float对齐值为4字节，指针和double的对齐值和体系结构有关，32位系统下，指针和double的对齐值为4字节，64位系统下则为8字节。注意在32位系统下，double类型的大小为8字节，但对齐值为4字节。 32位系统下的系统对齐值为4字节，64位系统下的系统对齐值为8字节。 成员变量相对于结构体起始位置的偏移，必须是该成员对齐值与系统对齐值这两者较小值的整数倍。 整个结构体的大小，必须是结构体对齐值的整数倍。结构体对齐值为系统对齐值与结构体成员中的最大对齐值这两者的较小值。 例如 12345678910111213141516171819202122#include &lt;iostream&gt;using namespace std;struct st1{ char a ; int b ; short c ;}; struct st2{ short c ; char a ; int b ;}; int main(){ cout&lt;&lt;&quot;sizeof(st1) is &quot;&lt;&lt;sizeof(st1)&lt;&lt;endl; //sizeof(st1) is 12 cout&lt;&lt;&quot;sizeof(st2) is &quot;&lt;&lt;sizeof(st2)&lt;&lt;endl; //sizeof(st2) is 8 return 0 ;}","link":"/C_C++/%E5%85%B3%E4%BA%8E%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/"},{"title":"数据模型","text":"数据模型 Data Type ILP32 LP32 ILP64 LP64 LLP64 宏定义 __LP64__ __LLP64__ 平台 Win32 API / Unix 和 Unix 类的系统 （Linux，Mac OS X） Win16 API Unix 和 Unix 类的系统 （Linux，Mac OS X) Win64 API char 8 8 8 8 8 short 16 16 16 16 16 int 32 16 64 32 32 long 32 32 64 64 32 long long 64 64 64 64 64 void* 32 32 64 64 64 ILP32 指int,long和pointer 是 32 位的 LP32 指long和pointer是 32 位的 ILP64 指 int,long,long long和pointer 是 64 位 LP64 意思是long,long long和pointer是 64 位 LLP64 指long long和pointer是 64-bit 的","link":"/C_C++/%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/"},{"title":"Liunx使用Docker编译web项目","text":"Liunx使用Docker编译web 项目作者:Charming_Zhang 1. 安装Docker安装实例可以参考Docker安装 下载docker地址 注意：建议docker 使用21以上版本，否则运行node 项目会出现错误： 123456789101112node[1]: ../src/node_platform.cc:68:std::unique_ptr&lt;long unsigned int&gt; node::WorkerThreadsTaskRunner::DelayedTaskScheduler::Start(): Assertion `(0) == (uv_thread_create(t.get(), start_thread, this))' failed. 1: node::Abort() [node] 2: [node] 3: node::WorkerThreadsTaskRunner::WorkerThreadsTaskRunner(int) [node] 4: node::NodePlatform::NodePlatform(int, v8::TracingController*, v8::PageAllocator*) [node] 5: node::V8Platform::Initialize(int) [node] 6: [node] 7:node::Start(int, char**) [node] 8:[/lib/x86_64-linux-gnu/libc.so.6] 9: __libc_start_main [/lib/x86_64-linux-gnu/libc.so.6]10:_start [node]ERROR: script returned exit code 139 2. 安装Node 镜像2.1. 配置daemon.json daemon.json 的路径是 /etc/docker/daemon.json 为了解决不能下载镜像的问题，需要配置daemon.json 123456789101112131415{ &quot;registry-mirrors&quot;: [ &quot;https://hub-mirror.c.163.com&quot;, &quot;https://mirror.baidubce.com&quot;, &quot;https://ccr.ccs.tencentyun.com&quot;, &quot;https://docker.m.daocloud.io&quot;, &quot;https://docker.imgdb.de&quot;, &quot;https://docker-0.unsee.tech&quot;, &quot;https://docker.hlmirror.com&quot;, &quot;https://docker.1ms.run&quot;, &quot;https://func.ink&quot;, &quot;https://lispy.org&quot;, &quot;https://docker.xiaogenban1993.com&quot; ]} 2.2. 安装node12# 这里的版本要看自己web端使用的node版本docker pull node:21.1.0 安装成功后可以通过以下命令查看 1docker images 3. 在镜像中安装pnpm DockerFile内容 1234# 使用官方的 Node.js 镜像FROM node:21.1.0 as build-stage# 安装pnpmRUN corepack enable &amp;&amp; corepack prepare pnpm@latest --activate 运行命令 1docker build -t wisemap_node:1.0 . 4. 编译项目 需要运行的代码 1docker run --rm -v /home/ServerManager:/home/ServerManager wisemap_node:1.0 /bin/bash /home/ServerManager/zzbuild.sh build.sh的代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#!/bin/bash#get current path and parent pathexport current_path=&quot;$( cd &quot;$( dirname &quot;${BASH_SOURCE[0]}&quot; )&quot; &amp;&amp; pwd )&quot;export parent_path=&quot;$( cd &quot;$( dirname &quot;${BASH_SOURCE[0]}&quot; )/../&quot; &amp;&amp; pwd )&quot;#set absolute path of the node componentexport pnpm_store_path=$parent_path/WiseMapWebStore/.pnpm-store#using legacy behavior of OpenSSLexport NODE_OPTIONS=--openssl-legacy-provider#study parameterwhile [ $# -gt 0 ]; do case &quot;$1&quot; in --help) echo &quot;Options:&quot; echo &quot; --prefix [set install prefix]&quot; exit 0 ;; *) echo &quot;The command is not recognized: $1&quot; echo &quot;$0 --help to show help&quot; exit 1 ;; esac shiftdone#chdircd $current_path || exit 1#set config of pnpmpnpm config set store-dir $pnpm_store_path || exit 1pnpm config set global-bin-dir $pnpm_store_path || exit 1pnpm config set strict-ssl false || exit 1#show config of pnpmecho &quot;set pnpm store-dir to $(pnpm config get store-dir)&quot;echo &quot;set pnpm global-bin-dir $(pnpm config get global-bin-dir)&quot;#install dependspnpm install || exit 1#build servicepnpm run build || exit 1 5. 运行项目1docker run --rm --network -v /home/ServerManager:/home/ServerManager wisemap_node:1.0 /bin/bash /home/ServerManager/zzserver.sh 5.1 解决docker network 问题1、开启防火墙 1systemctl start firewalld 2、开放指定端口 1firewall-cmd --zone=public --add-port=8848/tcp --permanent 3、重启防火墙 1firewall-cmd --reload 4、查看端口号命令 1netstat -ntlp 5.2 可以通过浏览器访问链接了 http://localhost:8848/","link":"/Docker/Liunx%E4%BD%BF%E7%94%A8Docker%E7%BC%96%E8%AF%91web%E9%A1%B9%E7%9B%AE/"},{"title":"kubernetes部署服务","text":"目录 Pod 基础命令 YAML方式创建Pod 实际部署 Deployment 基础命令 YAML方式创建Deployment 实际部署 Service 基础命令 实际部署 PVC 实际应用 列举一下会用到的docker国内加速镜像将以下内容写入/etc/docker/daemon.json即可 daemon.json 12345678910111213{ &quot;registry-mirrors&quot;: [ &quot;https://ccr.ccs.tencentyun.com&quot;, &quot;https://docker.m.daocloud.io&quot;, &quot;https://docker.imgdb.de&quot;, &quot;https://docker-0.unsee.tech&quot;, &quot;https://docker.hlmirror.com&quot;, &quot;https://docker.1ms.run&quot;, &quot;https://func.ink&quot;, &quot;https://lispy.org&quot;, &quot;https://docker.xiaogenban1993.com&quot; ]} Pod基础命令创建一个nginx Pod 123456#创建一个nginx pod#--image 指定镜像#-n 指定命名空间kubectl run mynginx --image=nginx:1.14 -n swgx#镜像也可以指定完整镜像地址kubectl run mynginx --image=docker.1ms.run/nginx:latest -n swgx 获取Pod的信息 1234#获取pod信息#-o wide 显示更详细的信息kubectl get pod -n swgxkubectl get pod -o wide -n swgx 查看指定Pod的详情 12#查看pod详细信息kubectl describe pod mynginx -n swgx 查看Pod的运行日志（容器启动命令的输出内容） 12#查看pod的运行日志kubectl logs mynginx -n swgx 测试部署成功的nginx 12#查看部署成功的nginx，ip可以在'kubectl get pod -o wide -n swgx'这条命令看到curl 172.168.224.37:80 以命令行的形式进入pod 12#以命令行的形式进入podkubectl exec -n swgx -it mynginx -- /bin/bash 删除Pod 12#删除podkubectl delete pod mynginx -n swgx YAML方式创建Pod创建nginx-swgx.yaml并写入如下内容 nginx-swgx.yaml 123456789101112131415161718192021222324252627282930apiVersion: v1#类型kind: Podmetadata: #Pod名称 name: mynginx #命名空间 namespace: swgxspec: #容器 containers: #容器名称 - name: nginx #容器镜像 image: docker.1ms.run/nginx:latest #容器端口 ports: - containerPort: 80 #容器挂载目录 volumeMounts: - name: nfs-data mountPath: /usr/share/nginx/html #目录 volumes: #目录 - name: nfs-data #nsf服务 nfs: server: 172.16.104.24 path: /home/nfs-master1/test-master1-data-storage-pvc-e94219f3-2ef7-4056-a3b1-d830e4b5bda0/wisemap/WiseMapGisServer-v6.2.0-28067/webserverextensions/www/help/webapi 创建Pod 123#yaml方式创建pod#-f 指定yaml文件kubectl create -f nginx-swgx.yaml 实际部署先运行一个可以持续存在的进程保证容器持久存在，然后进入容器进行wisemap的依赖项配置 创建wisemap_tmp.yaml并写入如下内容，这会创建一个容器运行tail进程保证容器的存在 wisemap_tmp.yaml 123456789101112131415161718192021222324apiVersion: v1kind: Podmetadata: name: wisemap namespace: swgxspec: containers: - name: wisemapserver image: docker.1ms.run/ubuntu:16.04 env: - name: LANG value: C.UTF-8 - name: LC_ALL value: C.UTF-8 command: [&quot;tail&quot;] args: [&quot;-f&quot;, &quot;/dev/null&quot;] volumeMounts: - name: nfs-wisemap mountPath: /opt/WiseMapGisServer-v6.2.0-28067 volumes: - name: nfs-wisemap nfs: server: 172.16.104.24 path: /home/nfs-master1/test-master1-data-storage-pvc-e94219f3-2ef7-4056-a3b1-d830e4b5bda0/wisemap/WiseMapGisServer-v6.2.0-28067 然后进入容器进行依赖项配置并测试服务能否启动，测试完成后删除Pod以及wisemap_tmp.yaml 1234#进入容器kubectl exec -n swgx -it wisemap -- /bin/bash#配置wisemap完成之后删除Podkubectl delete pod wisemap -n swgx 接下来正式创建wisemap Pod创建wisemap.yaml并写入如下内容 wisemap.yaml 12345678910111213141516171819202122232425262728293031323334353637383940apiVersion: v1kind: Podmetadata: name: wisemap namespace: swgxspec: containers: - name: wisemapserver image: docker.1ms.run/ubuntu:16.04 env: - name: LANG value: C.UTF-8 - name: LC_ALL value: C.UTF-8 command: [&quot;/opt/WiseMapGisServer-v6.2.0-28067/server/bin/mgserver.sh&quot;] volumeMounts: - name: nfs-wisemap mountPath: /opt/WiseMapGisServer-v6.2.0-28067 - name: wisemaphttp image: docker.1ms.run/ubuntu:16.04 env: - name: LANG value: C.UTF-8 - name: LC_ALL value: C.UTF-8 command: [ &quot;/opt/WiseMapGisServer-v6.2.0-28067/webserverextensions/apache2/bin/apachectl&quot;, ] args: [&quot;-D&quot;, &quot;FOREGROUND&quot;] ports: - containerPort: 8008 volumeMounts: - name: nfs-wisemap mountPath: /opt/WiseMapGisServer-v6.2.0-28067 volumes: - name: nfs-wisemap nfs: server: 172.16.104.24 path: /home/nfs-master1/test-master1-data-storage-pvc-e94219f3-2ef7-4056-a3b1-d830e4b5bda0/wisemap/WiseMapGisServer-v6.2.0-28067 创建wisemap Pod 1kubectl create -f ./wisemap.yaml 发送一个创建session的请求来验证是否部署成功 1kubectl describe pod wisemap -n swgx | grep &quot;^IP: &quot; | awk '{print $2}' | xargs -i curl 'http://{}:8008/WiseMap/mapagent/mapagent.fcgi?OPERATION=CREATESESSION&amp;VERSION=4.0.0&amp;LOCALE=&amp;CLIENTAGENT=&amp;SESSION=' -w '\\n' Deployment基础命令创建Deployment 12345#创建一个nginx Deployment#--image 指定镜像#-n 指定命名空间#--replicas 指定副本数量kubectl create deployment mynginx --image=docker.1ms.run/nginx:latest -n swgx --replicas=3 获取Deployment的信息 12#获取Deployment的信息kubectl get deployment -o wide -n swgx 查看指定Deployment的详情 12#查看Deployment详细信息kubectl describe deployment mynginx -n swgx 删除Deployment 12#删除Deploymentkubectl delete deployment mynginx -n swgx YAML方式创建Deployment创建nginx-swgx.yaml并写入如下内容 nginx-swgx.yaml 123456789101112131415161718192021222324252627282930313233apiVersion: apps/v1#类型kind: Deploymentmetadata: #Deployment名称 name: mynginx-deployment #命名空间 namespace: swgxspec: #副本数 replicas: 3 selector: matchLabels: app: mynginx #Pod模板 template: metadata: labels: app: mynginx spec: containers: - name: mynginx image: docker.1ms.run/nginx:latest ports: - containerPort: 80 volumeMounts: - name: nfs-data mountPath: /usr/share/nginx/html volumes: - name: nfs-data nfs: server: 172.16.104.24 path: /home/nfs-master1/test-master1-data-storage-pvc-e94219f3-2ef7-4056-a3b1-d830e4b5bda0/wisemap/WiseMapGisServer-v6.2.0-28067/webserverextensions/www/help/webapi 创建Deployment 1kubectl create -f nginx-swgx.yaml 实际部署创建wisemap.yaml并写入如下内容 wisemap.yaml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849apiVersion: apps/v1kind: Deploymentmetadata: name: wisemap-deployment namespace: swgxspec: replicas: 1 selector: matchLabels: app: wisemap template: metadata: labels: app: wisemap spec: containers: - name: wisemapserver image: docker.1ms.run/ubuntu:16.04 env: - name: LANG value: C.UTF-8 - name: LC_ALL value: C.UTF-8 command: [&quot;/opt/WiseMapGisServer-v6.2.0-28067/server/bin/mgserver.sh&quot;] volumeMounts: - name: nfs-wisemap mountPath: /opt/WiseMapGisServer-v6.2.0-28067 - name: wisemaphttp image: docker.1ms.run/ubuntu:16.04 env: - name: LANG value: C.UTF-8 - name: LC_ALL value: C.UTF-8 command: [ &quot;/opt/WiseMapGisServer-v6.2.0-28067/webserverextensions/apache2/bin/apachectl&quot;, ] args: [&quot;-D&quot;, &quot;FOREGROUND&quot;] ports: - containerPort: 8008 volumeMounts: - name: nfs-wisemap mountPath: /opt/WiseMapGisServer-v6.2.0-28067 volumes: - name: nfs-wisemap nfs: server: 172.16.104.24 path: /home/nfs-master1/test-master1-data-storage-pvc-e94219f3-2ef7-4056-a3b1-d830e4b5bda0/wisemap/WiseMapGisServer-v6.2.0-28067 Service基础命令暴漏服务 12kubectl expose deployment mynginx-deployment --port=80 --type=NodePort -n swgxkubectl expose deployment wisemap-deployment --port=8008 --type=NodePort -n swgx 获取Service的信息 12#获取Service的信息kubectl get service -o wide -n swgx 查看指定Service的详情 123#查看Service详细信息kubectl describe service mynginx-deployment -n swgxkubectl describe service wisemap-deployment -n swgx 删除Service 123#删除Servicekubectl delete service mynginx-deployment -n swgxkubectl delete service wisemap-deployment -n swgx 实际部署更新wisemap.yaml wisemap.yaml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263apiVersion: apps/v1kind: Deploymentmetadata: name: wisemap-deployment namespace: swgxspec: replicas: 1 selector: matchLabels: app: wisemap template: metadata: labels: app: wisemap spec: containers: - name: wisemapserver image: docker.1ms.run/ubuntu:16.04 env: - name: LANG value: C.UTF-8 - name: LC_ALL value: C.UTF-8 command: [&quot;/opt/WiseMapGisServer-v6.2.0-28067/server/bin/mgserver.sh&quot;] volumeMounts: - name: nfs-wisemap mountPath: /opt/WiseMapGisServer-v6.2.0-28067 - name: wisemaphttp image: docker.1ms.run/ubuntu:16.04 env: - name: LANG value: C.UTF-8 - name: LC_ALL value: C.UTF-8 command: [ &quot;/opt/WiseMapGisServer-v6.2.0-28067/webserverextensions/apache2/bin/apachectl&quot;, ] args: [&quot;-D&quot;, &quot;FOREGROUND&quot;] ports: - containerPort: 8008 volumeMounts: - name: nfs-wisemap mountPath: /opt/WiseMapGisServer-v6.2.0-28067 volumes: - name: nfs-wisemap nfs: server: 172.16.104.24 path: /home/nfs-master1/test-master1-data-storage-pvc-e94219f3-2ef7-4056-a3b1-d830e4b5bda0/wisemap/WiseMapGisServer-v6.2.0-28067---apiVersion: v1kind: Servicemetadata: name: wisemap-service namespace: swgxspec: selector: app: wisemap ports: - port: 8008 targetPort: 8008 nodePort: 38008 type: NodePort PVC实际应用先将服务包拷贝到pvc中 创建wisemap_testpvc.yaml并写入如下内容 wisemap_testpvc.yaml 1234567891011121314151617181920212223242526272829apiVersion: v1kind: Podmetadata: name: wisemap namespace: swgxspec: containers: - name: wisemapserver image: docker.1ms.run/ubuntu:16.04 env: - name: LANG value: C.UTF-8 - name: LC_ALL value: C.UTF-8 command: [&quot;tail&quot;] args: [&quot;-f&quot;, &quot;/dev/null&quot;] volumeMounts: - name: nfs-wisemap mountPath: /opt/WiseMapGisServer-v6.2.0-28067 - name: swgx-ce-pvc mountPath: /opt/test_pvc volumes: - name: nfs-wisemap nfs: server: 172.16.104.24 path: /home/nfs-master1/test-master1-data-storage-pvc-e94219f3-2ef7-4056-a3b1-d830e4b5bda0/wisemap/WiseMapGisServer-v6.2.0-28067 - name: swgx-ce-pvc persistentVolumeClaim: claimName: swgx-ce-pvc 执行如下shell来拷贝服务包 1234567891011#创建Podkubectl create -f wisemap_testpvc.yaml#进入Podkubectl exec -n swgx -it wisemap -- /bin/bash#创建目录并拷贝包mkdir -p /opt/test_pvc/swgx/WiseMapGisServer-v6.2.0-28067cp -Rpf /opt/WiseMapGisServer-v6.2.0-28067/* /opt/test_pvc/swgx/WiseMapGisServer-v6.2.0-28067/#退出Podexit#删除Podkubectl delete pod wisemap -n swgx 创建Deployment 创建wisemap.yaml并写入如下内容 wisemap.yaml 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364apiVersion: apps/v1kind: Deploymentmetadata: name: wisemap-deployment namespace: swgxspec: replicas: 1 selector: matchLabels: app: wisemap template: metadata: labels: app: wisemap spec: containers: - name: wisemapserver image: docker.1ms.run/ubuntu:16.04 env: - name: LANG value: C.UTF-8 - name: LC_ALL value: C.UTF-8 command: [&quot;/opt/WiseMapGisServer-v6.2.0-28067/server/bin/mgserver.sh&quot;] volumeMounts: - name: swgx-ce-pvc mountPath: /opt/WiseMapGisServer-v6.2.0-28067 subPath: swgx/WiseMapGisServer-v6.2.0-28067 - name: wisemaphttp image: docker.1ms.run/ubuntu:16.04 env: - name: LANG value: C.UTF-8 - name: LC_ALL value: C.UTF-8 command: [ &quot;/opt/WiseMapGisServer-v6.2.0-28067/webserverextensions/apache2/bin/apachectl&quot;, ] args: [&quot;-D&quot;, &quot;FOREGROUND&quot;] ports: - containerPort: 8008 volumeMounts: - name: swgx-ce-pvc mountPath: /opt/WiseMapGisServer-v6.2.0-28067 subPath: swgx/WiseMapGisServer-v6.2.0-28067 volumes: - name: swgx-ce-pvc persistentVolumeClaim: claimName: swgx-ce-pvc---apiVersion: v1kind: Servicemetadata: name: wisemap-service namespace: swgxspec: selector: app: wisemap ports: - port: 8008 targetPort: 8008 nodePort: 38008 type: NodePort 应用此yaml即可","link":"/Kubernetes/kubernetes%E9%83%A8%E7%BD%B2%E6%9C%8D%E5%8A%A1/"},{"title":"Linux动态库的查找方式与优先级","text":"第一种方法:rpath在链接时语句后面添加如下命令 12#编译设置rpath-Wl,-rpath=&lt;rpath &gt; 第二种方法:LD_LIBRARY_PATH设置环境变量LD_LIBRARY_PATH 1export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:&lt;path&gt; 第三种方法:/lib、/usr/lib/lib、/usr/lib文件夹是系统默认的搜索路径。将库文件放置在其中，运行时就可以搜索到了。 第四种方法:/etc/ld.so.cache通过修改配置文件/etc/ld.so.conf中指定的动态库搜索路径，然后执行ldconfig命令来应用。 优先级方法一 &gt; 方法二 &gt; 方法三 &gt; 方法四","link":"/Linux/Linux%E5%8A%A8%E6%80%81%E5%BA%93%E7%9A%84%E6%9F%A5%E6%89%BE%E6%96%B9%E5%BC%8F%E4%B8%8E%E4%BC%98%E5%85%88%E7%BA%A7/"},{"title":"Linux输出重定向","text":":重定向,但是会删除原先内容 :重定向,不会删除原本内容,会在后边追加 linux中1代表标准输出，2代表的是标准错误输出，/dev/nulll等价于一个只写文件. 所有写入它的内容都会永远丢失 ls xxx &gt;/dev/null 2&gt;&amp;1这个命令的意思就是将ls xxx命令的标准输出重定向到/dev/null中，然后将标准错误输出重定向到标准输出中,这样运行的结果就什么都不会输出了。 ls xxx &gt;/dev/null 2&gt;&amp;1也可以写成ls xxx 1&gt;/dev/null 2&gt;&amp;1 但是&gt;/dev/null 2&gt;&amp;1的顺序不能换，如果顺序颠倒写成|ls xxx 2&gt;&amp;1 1&gt;/dev/null的后果就是标准输出定位到了/dev/null中，但是标准错误输出还是会打印在屏幕上。 可以理解成shell脚本是从做往右读取的，如果在输出标准错误时读取到了2&gt;&amp;1那么就会认为标准错误要输出到标准输出中，不会往右继续读了。 12[root@localhost lib64]# find ./ -name &quot;*FDO*&quot; | xargs ldd 2&gt;&amp;1 1&gt;/dev/nullldd: warning: you do not have execution permission for `./FDO.py' 可以看到如果写反了，标准错误还是会被打印出来。","link":"/Linux/Linux%E8%BE%93%E5%87%BA%E9%87%8D%E5%AE%9A%E5%90%91/"},{"title":"linux core文件生成设置","text":"设置与查看core文件大小限制1234ulimit -c unlimited #不限制core文件大小ulimit -c 1024 #限制大小为1024ulimit -c #查看core文件限制 查看core文件生成路径1234#查看路径sysctl kernel.core_pattern#或者cat /proc/sys/kernel/core_pattern 设置core文件生成路径临时修改：使用sysctl -w name=value命令。例： 1sysctl -w kernel.core_pattern=/data/core/core-%e-%t-%p.core 永久修改:将其添加到/etc/sysctl.conf中 1kernel.core_pattern=/data/core/core-%e-%t-%p.core core文件路径可通过以下占位符进行丰富 %p - pid(进程id)%u - 当前uid(用户id)%g - 当前gid(用户组id)%s - 导致产生core的信号%t - core文件生成时的unix时间%h - 主机名%e - 导致产生core的命令名","link":"/Linux/linux-core%E6%96%87%E4%BB%B6%E7%94%9F%E6%88%90%E8%AE%BE%E7%BD%AE/"},{"title":"linux自动拷贝依赖项","text":"​ 一般来说如果server在一台机器上部署好了之后再拷贝到别的机器上会出现动态库缺失的情况，需要在两台机器来回拷贝动态库十分麻烦，于是需要一个脚本，用来一键拷贝依赖的所有动态库，在需要部署的机器上会检测每个动态库是否缺失并且把缺失的动态库拷贝到指定目录下。 先放出脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#!/bin/bashif [ &quot;$#&quot; = &quot;0&quot; ]; then echo &quot;Error: please add option.&quot;; exit 1fiACTION=make #[make|check-and-use]#应用程序的安装目录APPDIR=/opt/app#应用程序所有依赖项的存放目录APPDEPALL=$APPDIR/dependencies/dep-all#应用程序在实际部署时缺少的动态库要拷贝到目录，这个目录要在应用程序运行前加到LD_LIBRARY_PATH环境变量里APPDEP=$APPDIR/dependencies/depwhile [ $# -gt 0 ]; do # Until you run out of parameters... case &quot;$1&quot; in --make) ACTION=make ;; --check-and-use) ACTION=check-and-use ;; --help) echo &quot;Options:&quot; echo &quot; --make [Make a dependency package]&quot; echo &quot; --check-and-use [Check and use dependent packages]&quot; echo &quot; --help [show help]&quot; exit ;; *) echo &gt;&amp;2 'copyDependencies.sh:' $&quot;unrecognized option&quot; &quot;\\`$1'&quot; echo &gt;&amp;2 $&quot;Try \\`copyDependencies.sh --help' for more information.&quot; exit 1 ;; esac shift # Check next set of parameters.doneif [ &quot;$ACTION&quot; = &quot;make&quot; ]; then #在这里可以根据自己的需要设置LD_LIBRARY_PATH,让ldd命令可以正确的找到动态库 export LD_LIBRARY_PATH=&quot;$LD_LIBRARY_PATH&quot; #下面这个命令通过管道和ldd命令搜索出来应用程序以来的所有的动态库，并将他们拷贝到APPDEPALL目录 find &quot;$APPDIR/&quot; -type f | grep -v &quot;^$APPDEPALL/&quot; | xargs -i file -F &quot; // &quot; &quot;{}&quot; | grep -E &quot; // [ ]{0,}ELF&quot; | awk -F &quot; // &quot; '{print $1}' | xargs -i ldd {} | awk -F &quot; =&gt; &quot; '{ if(NF==2) print $2}' | awk -F &quot; [(]{1}0x[0-9a-f]{16}[)]{1}$&quot; '{ if(NF==2) print $1}' | grep -v &quot;^$APPDIR/&quot; | xargs -i \\cp -L -n &quot;{}&quot; &quot;$APPDEPALL/&quot;else #ldconfig -p列出当前部署环境的动态库，如果没有则将动态库拷贝到APPDEP目录 for filename in &quot;$APPDEPALL/&quot;* ; do basefilename=`basename &quot;$filename&quot;` ldre=`ldconfig -p | grep &quot;/$basefilename\\$&quot;` if [ -z &quot;$ldre&quot; ]; then echo copy &quot;$basefilename&quot; to &quot;$APPDEP/&quot; \\cp -L -n &quot;$filename&quot; &quot;$APPDEP/&quot; fi done #有时虽然有同名的动态库，但是两个库的版本信息不一致导致程序不能启动，这是需要通过一下命令检测版本信息，如果缺少版本信息则将动态库拷贝到APPDEP目录 #以下命令参考了rpm的find-requires脚本，路径是/usr/lib/rpm/find-requires whereisobjdump=`whereis objdump` if [ ! &quot;$whereisobjdump&quot; = &quot;objdump:&quot; ]; then for checkobj in &quot;$APPDIR/server/bin/mgserver&quot; &quot;$APPDIR/webserverextensions/apache2/bin/httpd&quot; ; do reqverinfos=`objdump -p &quot;$checkobj&quot; | awk 'BEGIN { START=0; LIBNAME=&quot;&quot;; } /^[ ]{0,}required from .*:$/ { START=1; } (START==1) &amp;&amp; /required from / { sub(/:/, &quot;&quot;, $3); LIBNAME=$3; } (START==1) &amp;&amp; (LIBNAME!=&quot;&quot;) &amp;&amp; ($4!=&quot;&quot;) { print LIBNAME&quot; ----- &quot;$4; } '` echo &quot;$reqverinfos&quot; | while read reqverinfo do LIBNAME=`echo $reqverinfo | awk -F &quot; ----- &quot; '{print $1}'` VERSION=`echo $reqverinfo | awk -F &quot; ----- &quot; '{print $2}'` if [ ! X&quot;$LIBNAME&quot; = X -a ! X&quot;$VERSION&quot; = X -a ! -f &quot;$APPDEP/$LIBNAME&quot; ]; then ldre=`ldconfig -p | grep &quot;/$LIBNAME\\$&quot; | awk -F &quot; =&gt; &quot; '{print $2}'` findre=`strings &quot;$ldre&quot; | grep &quot;^$VERSION\\$&quot;` if [ -z &quot;$findre&quot; ]; then echo copy &quot;$LIBNAME&quot; to $APPDEP/ \\cp -L -n &quot;$APPDEPALL/$LIBNAME&quot; &quot;$APPDEP/&quot; fi fi done done else echo &quot;objdump executable file not found, please check the dynamic library version information by yourself&quot; fifi 解释一下 参数参数–make的作用是制作依赖项包，就是把所有的依赖项拷贝到APPDEPALL目录参数–check-and-use在部署是用，作用是在部署环境中检测哪些动态库缺失，并把缺失的动态库拷贝到APPDEP目录里。 目录APPDIR是要部署的软件的安装目录，APPDEPALL是软件所有的动态库依赖项的存放目录，APPDEP是实际部署时哪些库缺少了就把哪些库拷贝到这些目录下。为什么要有APPDEP这个目录，是因为在制作APPDEPALL时并不会检测哪些时系统的库，如果无区别的吧这些库都加到部署环境的环境变量里会导致很多基础的命令都用不了（亲测是这样的，因为一些底层的库不匹配，因此需要谨慎）。 拷贝拷贝命令有点长，解释一下 find “$APPDIR/“ -type f | grep -v “^$APPDEPALL/“查找软件安装目录下的所有文件，并过滤掉APPDEPALL目录下的动态库 find “$APPDIR/“ -type f | grep -v “^$APPDEPALL/“ | xargs -i file -F “ // “ “{}” | grep -E “ // [ ]{0,}ELF” | awk -F “ // “ ‘{print $1}’在上一步的查找结果里筛选出来动态库，根据file命令筛选 find “$APPDIR/“ -type f | grep -v “^$APPDEPALL/“ | xargs -i file -F “ // “ “{}” | grep -E “ // [ ]{0,}ELF” | awk -F “ // “ ‘{print $1}’ | xargs -i ldd {} | awk -F “ =&gt; “ ‘{ if(NF==2) print $2}’ | awk -F “ [(]{1}0x[0-9a-f]{16}[)]{1}$” ‘{ if(NF==2) print $1}’ | grep -v “^$APPDIR/“ | xargs -i \\cp -L -n “{}” “$APPDEPALL/“用ldd命令查看这些动态库的依赖项，并排除掉APPDIR目录下的动态库，最后进行拷贝 使用用ldconfig -p列出当前部署环境的动态库，如果没有则将动态库拷贝到APPDEP目录 有时虽然有同名的动态库，但是两个库的版本信息不一致导致程序不能启动，这是需要通过一下命令检测版本信息，如果缺少版本信息则将动态库拷贝到APPDEP目录，62-86行参考了rpm的find-requires脚本，路径是/usr/lib/rpm/find-requires 注意这个脚本只能尽可能包整动态库依赖的完整性，根据实际情况的不同需要人为去进行控制。","link":"/Linux/linux%E8%87%AA%E5%8A%A8%E6%8B%B7%E8%B4%9D%E4%BE%9D%E8%B5%96%E9%A1%B9/"},{"title":"记录部署服务时遇到的glibc版本冲突问题","text":"发现问题某天在linux下部署服务时出现了因为glibc版本不匹配导致服务无法启动的问题。 1/lib64/libm.so.6: version `GLIBC_2.27' not found 一般在打包的时候我会把编译机器上所有服务依赖的动态库拷贝到一个文件夹下，在部署服务的时候会动态检测缺少什么动态库，然后把对应的动态库拷贝到另一个文件夹再把这个文件夹加入到LD_LIBRARY_PATH环境变量，但是因为版本不匹配（`GLIBC_2.27’ not found）导致的动态库冲突有时会检测不出来，这时就必须要手动拷贝，一般只拷贝libpthread.so或者libm.so这种问题都不大，但是拷贝到最后出现了这样的错误： 1symbol __tunable_get_val, version GLIBC_PRIVATE not defined in file ld-linux-aarch64.so.1 动态链接器符号竟然找不到。 经过排查发现打包机器的glibc版本是2.31，部署机器的glibc版本时2.17，版本相差太多了。 尝试解决由于动态链接器是硬编码到文件里的，而且不能随意的把其他的版本动态链接器替换到目标机器上，因此需要想办法去替换动态链接器，用到的工具有：patchelf、对应的glibc库。 1patchelf --set-interpreter /glibc-2.31-binary/lib/ld-linux-aarch64.so.1 /custom/program 用这个命令把你的动态链接器路径硬编码到你的程序中。 在启动脚本前加上： 123export LD_PRELOAD=/custom1/ld-linux-aarch64.so.1#/glibc-2.31-binary/lib/aarch64-linux-gnu文件夹是目标版本glibc的一些库，pthread、m等export LD_LIBRARY_PATH=/glibc-2.31-binary/lib:/glibc-2.31-binary/lib/aarch64-linux-gnu:&quot;$LD_LIBRARY_PATH&quot; 如果没有对应版本的glibc库则把打包机器的链接器拷贝过来也是一样的效果，所有服务依赖的动态库的文件夹要加入到LD_LIBRARY_PATH环境变量。 这样一番操作下来服务终于启动了起来，但是还是有一些问题，**setlocale(LC_ALL, “”)这个函数返回了空指针，调用setlocale(LC_ALL, “C”)**没有问题，服务运行中发现c++会抛异常 1locale::facet::_S_create_c_locale name not valid 应该是一些本地化的配置没有设置好，或者信息丢失了，于是在启动脚本中加入 1export LC_ALL=C 这样直接导致服务在启动的时候抛出Could not load a transcoding service的异常并且启动失败，原因目前还没有找到。 总结以后在打包的时候打包机器的glibc版本尽量要小于等于目标机器的版本，可以选择一个较低的版本来支持各种常见的Linux发行版。 以下是常见的Linux发行版本的glibc版本（chatgpt） 12345Ubuntu：Ubuntu 14.04 LTS 及更高版本需要 glibc 2.19 或更高版本。Debian：Debian 8 及更高版本需要 glibc 2.19 或更高版本。CentOS：CentOS 7 需要 glibc 2.17 或更高版本，CentOS 8 需要 glibc 2.28 或更高版本。Fedora：Fedora 26 及更高版本需要 glibc 2.25 或更高版本。Arch Linux：Arch Linux 使用最新版本的 glibc。 因此打包所用的glibc尽量小于等于2.17 查看了一下达梦和瀚高在centos下的二进制包的glibc版本要求是2.10和2.14 用这个命令可以查看glibc最低要求 1find ./ -name &quot;lib*so*&quot; | xargs -i strings {} | grep -i glibc_ | awk -F &quot;@@&quot; '{print $2}' | sort | uniq","link":"/Linux/%E8%AE%B0%E5%BD%95%E9%83%A8%E7%BD%B2%E6%9C%8D%E5%8A%A1%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84glibc%E7%89%88%E6%9C%AC%E5%86%B2%E7%AA%81%E9%97%AE%E9%A2%98/"},{"title":"Hexo博客基本指南","text":"由于本人工作在内网，博客随缘更新，因此写一个关于hexo的文档，以免每次都要重新回忆一遍 1.下载依赖1234#全局下载npm install hexo-cli -g#项目中下载npm install 1234#查看全局下载内容npm ls -g#查看项目下载内容npm ls 2.hexo生成12hexo g#或hexo generate 该命令执行后在hexo站点根目录下生成public文件夹 3.hexo清理1hexo clean 把生成中的public文件夹删除 4.hexo本地启动12hexo s#或hexo server 启动服务，默认地址为http://localhost:4000 5.新建文章1hexo new [layout] &lt;title&gt; 指令执行时，Hexo 会尝试在 scaffolds 中寻找layout.md布局，若找到，则根据该布局新建文章；若未找到或指令中未指定该参数，则使用post.md新建文章。新建文章的名称在_config.yml中配置。 6.部署静态页面12hexo d#或hexo deploy 部署站点，在本地生成.deploy_git文件夹，并将编译后的文件上传","link":"/hexo/Hexo%E5%8D%9A%E5%AE%A2%E5%9F%BA%E6%9C%AC%E6%8C%87%E5%8D%97/"},{"title":"git基本使用流程","text":"配置代理（科学上网）1234567891011121314151617# 设置 HTTP/HTTPS 代理git config --global http.proxy http://127.0.0.1:7890git config --global https.proxy http://127.0.0.1:7890# 取消代理git config --global --unset http.proxygit config --global --unset https.proxy# 查看当前代理配置git config --get http.proxygit config --get https.proxy# 查看所有 git 配置git config --list#查看所有全局 git 配置git config --list --global ⚠️ 注意：部分情况下 https 代理可能无效，建议优先设置 http 代理。 配置正确显示中文路径1git config --global core.quotepath false 克隆代码1git clone git@github.com:ShawayL/HexoBlog.git 拉取代码1git pull 添加暂存区123git add .git add [file1] [file2] ...git add [dir] 提交暂存区文件1git commit -m &quot;message&quot; 推送本地提交到远程仓库1git push","link":"/git/git%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%E6%B5%81%E7%A8%8B/"},{"title":"PostgreSQL(PostGIS)安装与卸载","text":"PostgreSQL(PostGIS)安装第一步：安装PostgreSQL运行postgresql-11.10-1-windows-x64.exe。 选择安装目录，我的是”E:\\PostgreSQL\\11”。 全选，next。 存储路径选择默认路径，next。 为数据库默认超级账户 postgres 设置密码,next。 选择默认端口5432，next。 区域选择：默认，一直next，等待安装完毕。 是否运行拓展下载工具，取消勾选，Finish,安装完毕。 第二步：安装PostGIS拓展运行postgis-bundle-pg11x64-setup-3.0.2-1.exe。 勾选上Create spatial database，next。 选择PostgreSQL的安装目录，我的是”E:\\PostgreSQL\\11”，next。 输入安装中设置的默认超级账户 postgres 密码,next。 输入模板空间数据库名字，**需要从默认名字修改为：”template_postgis”** ,install。 是否添加GDAL_DATA环境变量用来进行栅格转换，这个操作可能会覆盖掉原有GDAL_DATA环境变量，选择否，如有需要可重新添加。 栅格驱动默认未开启，是否添加环境变量来开启，选择否，如有需要可重新添加。 导出栅格功能默认未开启，是否添加环境变量来开启，选择否，如有需要可重新添加。 安装完成。 PostgreSQL(PostGIS)卸载第一步：关闭PostgreSQL服务 关闭上图中PostgreSQL服务。 第二步：卸载PostGIS拓展 运行pg安装目录下uninstall-postgis-bundle-pg11x64-3.0.2-1.exe。 Uninstall，完成。 第三步：卸载PostgreSQL 运行PostgreSQL安装目录下uninstall-postgresql.exe。 选择第一个，Next，等待进度条结束。 删除PostgreSQL安装目录下残余文件。 删除pgAdmin文件夹，位于C:\\Users&quot;username”\\AppData\\Roaming\\下。","link":"/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/PostgreSQL(PostGIS)%E5%AE%89%E8%A3%85%E4%B8%8E%E5%8D%B8%E8%BD%BD/"},{"title":"原码、反码、补码、移码","text":"原码、反码、补码、移码 原码 反码 补码 移码 0的原码、反码、补码、移码 浮点数的二进制表示 浮点数加法运算 规格化 TODO 原码、反码、补码、移码原码、反码、补码和移码是计算机中表示和处理有符号数的几种方法。 原码原码是计算机中表示有符号数的一种最简单的方法。它使用最高位表示符号位，0表示正数，1表示负数，其余位表示数值的绝对值。例如，8位二进制数中，+5的原码表示为00000101，-5的原码表示为10000101。 表示范围：8位原码的表示范围为[-127~+127] 反码反码是对原码的一种改进表示方法。正数的反码与原码相同，负数的反码是对原码逐位取反（符号位除外）。例如，8位二进制数中，+5的反码表示为00000101，-5的反码表示为11111010。 表示范围：8位反码的表示范围为[-127~+127] 补码补码是计算机中最常用的表示有符号数的方法，常用于进行数字加减法。正数的补码与原码相同，负数的补码是其反码加1。例如，8位二进制数中，+5的补码表示为00000101，-5的补码表示为11111011。 表示范围：8位补码的表示范围为[-128~+127] 下表为4位补码与十进制的对应关系 补码 十进制 0111 7 0110 6 … … 0010 2 0001 1 0000 0 1111 −1 1110 −2 … … 1001 −7 1000 −8 以4位补码为例，可以将补码理解为在原数字的基础上进行了偏移处理的结果。补码的范围是0~15，而原数字的范围是-8~7。具体来说： 对于0和正数，补码的值与原数字相同，范围为0~7。 对于负数，补码的值是从最大值15开始向0偏移，范围为15~8。例如，-1的补码为15，-2的补码为14，依此类推，直到-8的补码为8。 补码可以简化有符号整数的加减法运算，将其都统一成补码的加法运算 1234 0011 (3) + 1111 (-1)-------------- 10010 (2) 移码移码通常用于表示浮点运算的阶码。无论正数负数，都是将该原码的补码的首位(符号位) 取反得到移码。例如，假设使用8位移码，则+5的移码表示为10000101，-5的移码表示为01111011。 在数轴上，移码所表示的范围，恰好对应于真值在数轴上的范围向正方向移动${2^{n}}$个单元 补码表示的好处在于去掉了负号，但人们很难从形式上判断真值大小，与人们的习惯不符;因为补码表示中符号也成了一位二进制的数，而移码的表示中与补码相差一个符号位，而且可以从移码看出真值的大小，转换方便。 补码 移码 十进制 0111 1111 7 0110 1110 6 … … … 0010 1010 2 0001 1001 1 0000 1000 0 1111 0111 −1 1110 0110 −2 … … … 1001 0001 −7 1000 0000 −8 0的原码、反码、补码、移码 原码 反码 补码 移码 +0 00000000 00000000 00000000 10000000 -0 10000000 11111111 00000000 10000000 浮点数的二进制表示下面以半精度浮点数为例 半精度浮点数的二进制表示主要包含：符号位(16)、指数位(15-11)、尾数(10-1) 符号位：浮点数的正负 指数位：表示浮点数的指数部分（采用偏移法表示） 尾数：表示浮点数的精确值 浮点数加法运算 首先先进性对阶，阶码小的向阶码大的对齐，同时尾数进行右移（变小）。 然后再对尾数进行加减法运算。 然后进行规格化处理（IEEE754）。 规格化1.对于原码表示的尾数 尾数最高有效位为1时，浮点数为规格化。2对于补码表示的尾数 当数符位与尾数最高有效位相异时，浮点数为规格化。 TODO","link":"/%E8%BD%AF%E8%80%83/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%E5%B8%88/%E5%8E%9F%E7%A0%81_%E5%8F%8D%E7%A0%81_%E8%A1%A5%E7%A0%81_%E7%A7%BB%E7%A0%81/"},{"title":"ElasticSearch开发手册","text":"ElasticSearch 开发手册作者:appolostar 开源的高扩展的分布式全文搜索引擎 elasticsearch与数据库的类比 关系型数据库（比如Mysql） 非关系型数据库（Elasticsearch） 数据库Database 索引Index 表Table 类型Type（7.0之后移除） 数据行Row 文档Document 数据列Column 字段Field 约束 Schema 映射Mapping 1、index、type的初衷之前es将index、type类比于关系型数据库（例如mysql）中database、table，这么考虑的目的是“方便管理数据之间的关系”。 【本来为了方便管理数据之间的关系，类比database-table 设计了index-type模型】 2、为什么现在要移除type？2.1 在关系型数据库中table是独立的（独立存储），但es中同一个index中不同type是存储在同一个索引中的（lucene的索引文件），因此不同type中相同名字的字段的定义（mapping）必须一致。 ES存入数据和搜索数据机制 (1)索引对象(blog):存储数据的表结构,任何搜索数据,存放在索引对象上(2)映射(mapping):数据如何存放在索引对象上,需要有一个映射配置,包括数据类型,是否存储,是否分词等(3)文档(document):一条数据记录,存在索引对象上(4)文档类型(type):一个索引对象,存放多种类型数据,数据用文档类型进行标识什么是分片 什么是分片 Elasticsearch集群允许系统存储的数据量超过单机容量，这是通过shard实现的。在一个索引index中，数据（document）被分片处理（sharding）到多个分片上。也就是说：每个分片都保存了全部数据中的一部分。 一个分片是一个 Lucene 的实例，它本身就是一个完整的搜索引擎。文档被存储到分片内，但应用程序直接与索引而不是与分片进行交互。 什么是副本说明 为了解决访问压力过大时单机无法处理所有请求的问题，Elasticsearch集群引入了副本策略replica。副本策略对index中的每个分片创建冗余的副本。 副本的作用如下： 提高系统容错性 当分片所在的机器宕机时，Elasticsearch可以使用其副本进行恢复，从而避免数据丢失。 提高ES查询效率 处理查询时，ES会把副本分片和主分片公平对待，将查询请求负载均衡到副本分片和主分片。 副本分片是越多越好吗？ 答案当然是 no ，原因有以下两点： （1）多个 replica 可以提升搜索操作的吞吐量和性能，但是如果只是在相同节点数目的集群上增加更多的副本分片并不能提高性能，因为每个分片从节点上获得的资源会变少，这个时候你就需要增加更多的硬件资源来提升吞吐量。 （2）更多的副本分片数提高了数据冗余量，保证了数据的完整性，但是根据上边主副分片之间的交互原理可知，分片间的数据同步会占用一定的网络带宽，影响效率，所以索引的分片数和副本数也不是越多越好。 一个节点就是集群中的一个服务器，也可以理解为，一个节点就是一个ES，作为集群的一部分，他储存数据，参与集群的索引和搜索功能，和集群类似，一个节点也是由一个名字来标识的，默认情况下，这个名字可以随意起，并且会在启动的时候赋予节点这个名字， 一个节点可以通过配置集群名称的方式来加入一个指定的集群。默认情况下，每个节点都会被安排加入到一个叫 做 “elasticsearch” 的集群中，这意味着，如果你在你的网络中启动了 若干个节点 ，并假定它们 能够相互发现彼此 ， 它们将会 自动地形成并加入 到一个叫做 “elasticsearch” 的集群中。 1.首先准备三台es服务器，我没有三台电脑，就一台电脑上启动三个es服务器，把我们原先的es文件夹复制三份， 2、 在yml文件中设置 这里我设置了三个节点组成的集群，如果想设置多个，就多创建几个服务器文件夹，然后修改里面的配置文件，并且每个node的端口号和名字都不能一样，设置各个node可以互相发现即可。 cluster-2和cluster-3和cluster-1是一样的操作。 ​ 3.当我们修改好了配置文件和创建新的服务器后，每个文件夹下的data目录里面一定要是空的，不能带任何内容。 4.我们把三个es服务器都启动 5.连接上es-header，grunt server，登陆head界面 ​ 输入我们服务器的端口号，这里我设置的是9201，9202，9203，结果都是一样的。 ​ 他们三个端口号的内容都是相同的，储存着一样的内容 一个节点在访问量和搜索量非常大的情况下，可能就会非常慢，或者某个节点中的分片负载太严重挂掉，而设置了集群，我们索引库的分片就会分散在各个分节点上，而且每个节点储存的分片是不相同的（相同的原分片和副本分片不会出现在同一个节点身上），这样就可以保证，我们大量用户搜索或者访问的时候，把我们的压力分散到每一个节点上示例1：启动2个ES节点。创建5个分片，1个副本 上图中，黄色的代表主分片，绿色的是副本。可以发现，分片与其副本不在同一个节点内。这是非常合理的，因为副本本来就是主分片的备胎，当主分片节点挂了，另外一个节点的副本将会充当主分片，如果它们在同一个节点内，副本将发挥不到作用。 7.分片 一个索引可以存储超出单个结点硬件限制的大量数据。比如，一个具有10亿文档的索引占据1TB的磁盘空间，而任 一节点都没有这样大的磁盘空间，或者单个节点处理搜索请求，响应太慢。为了解决这个问题，Elasticsearch提供 了将索引划分成多份的能力，这些份就叫做分片。当你创建一个索引的时候，你可以指定你想要的分片的数量。每个分片本身也是一个功能完善并且独立的“索引”，这个“索引”可以被放置到集群中的任何节点上。分片很重要，主要有两方面的原因：1）允许你水平分割/扩展你的内容容量。 2）允许你在分片（潜在地，位于多个节点上）之上进行分布式的、并行的操作，进而提高性能/吞吐量。 简单点来说就是，每个分片就包含了你索引库中的某一部分的内容，可以理解为一本书的目录（因为分片储存的就是索引），而分片是支持扩容的，当我们有大量的文档，由于内存不足，磁盘限制，速度极度下降，我们就需要扩容，这时一个节点就不够用了，所以我们需要把目录（分片）放到不同的空间中，也就是集群节点，这样当我们搜索某一个内容的时候，ES会把要查询的内容发给相关的分片，并将结果组合到一起。 安装基于Java语言开发的搜索引擎库类 官网：免费且开放的搜索：Elasticsearch、ELK 和 Kibana 的开发者 | Elastic 下载：Elasticsearch 8.3.2 | Elastic 解压： 配置环境： 由于es对java环境要求高，可以使用其内置的java环境，下面对其进行系统环境配置： 添加系统变量 将\\elasticsearch-8.3.2\\config下的主配置文件elasticsearch.yml进行修改： 修改： 123xpack.security.enabled: falseingest.geoip.downloader.enabled: false config/jvm.option配置文件，调整jvm堆内存大小： 修改： 123vim jvm.options-Xms4g-Xmx4g 建议不大于内存的一半 Xms和Xms设置成—样 直接运行elasticsearch.bat 运行http://localhost:9200/测试 如图效果正常 客户端Kibana安装Kibana是一个开源分析和可视化平台，旨在与Elasticsearch协同工作。 下载：Kibana 8.3.2 | Elastic 解压： 启动\\kibana-8.3.2\\bin下的kibana 访问Kibana: http://localhost:5601/ 出现该界面启动成功 ElasticSearch基本概念 传统关系型数据库和Elasticsearch的区别 在Elasticsearch中，文档归属于一种 类型(type) ,而这些类型存在于 索引(index)中，类比传统关系型数据库： Relational DB Databases Tables Rows Columns 关系型数据库 数据库 表 行 列 Elasticsearch Indices Types Documents Fields Elasticsearch 索引 类型 文档 域 在Elasticsearch中，所有的字段缺省都建了索引。 也就是说每一个字段都有一个倒排索引，用于快速查询。es支持http协议（json格式）（9200端口）、thrift、servlet、memcached、zeroMQ等的传输协议（通过插件方式集成）。传统关系型数据库不支持。es支持分片和复制，从而方便水平分割和扩展，复制保证了es的高可用与高吞吐。 索引（Index） 一个索引就是一个拥有几分相似特征的文档的集合。比如说，可以有一个客户数据的索引，另一个产品 目录的索引，还有一个订单数据的索引。 一个索引由一个名字来标识（必须全部是小写字母的），并且当我们要对对应于这个索引中的文档进行 索引、搜索、更新和删除的时候，都要使用到这个名字。 文档（Document） Elasticsearch是面向文档的，文档是所有可搜索数据的最小单位。 文档会被序列化成JSON格式，保存在Elasticsearch中 JSON对象由字段组成 每个字段都有对应的字段类型(字符串/数值/布尔/日期/二进制/范围类型) 每个文档都有一个Unique ID 可以自己指定ID或者通过Elasticsearch自动生成 一篇文档包含了一系列字段，类似数据库表中的一条记录 JSON文档，格式灵活，不需要预先定义格式 字段的类型可以指定或者通过Elasticsearch自动推算 支持数组/支持嵌套 ElasticSearch索引操作创建索引 索引命名必须小写，不能以下划线开头 格式: PUT /索引名称 123456789101112131415161718#创建索引PUT /es_text#创建索引时可以设置分片数和副本数PUT /es_text{&quot;settings&quot; : {&quot;number_of_shards&quot; : 3,&quot;number_of_replicas&quot; : 2}}#修改索引配置PUT /es_text/_settings{&quot;index&quot; : {&quot;number_of_replicas&quot; : 1}} 查询索引 1234#查询索引GET /es_db#es_text是否存在HEAD /es_db 删除索引 1DELETE /es_db ElasticSearch文档操作添加文档 格式: [PUT | POST] /索引名称/[_doc | _create ]/id 1234567891011121314151617181920212223242526# 创建文档,指定id# 如果id不存在，创建新的文档，否则先删除现有文档，再创建新的文档，版本会增加PUT /es_text/_doc/1{ &quot;name&quot;: &quot;qyc&quot;, &quot;sex&quot;: 1, &quot;age&quot;: 23, &quot;address&quot;: &quot;洛阳连飞中心大厦&quot;}POST /es_text/_doc{ &quot;name&quot;: &quot;lxw&quot;, &quot;sex&quot;: 1, &quot;age&quot;: 25, &quot;address&quot;: &quot;洛阳连飞中心大厦&quot;}PUT /es_text/_create/1{ &quot;name&quot;: &quot;hxf&quot;, &quot;sex&quot;: 1, &quot;age&quot;: 25, &quot;address&quot;: &quot;洛阳连飞中心大厦&quot;} POST和PUT都能起到创建/更新的作用，PUT需要对一个具体的资源进行操作也就是要确定id才能 进行更新/创建，而POST是可以针对整个资源集合进行操作的，如果不写id就由ES生成一个唯一id进行 创建新文档，如果填了id那就针对这个id的文档进行创建/更新 Create -如果ID已经存在，会失败 修改文档 全量更新，整个json都会替换，格式: [PUT | POST] /索引名称/_doc/id 如果文档存在，现有文档会被删除，新的文档会被索引 12345678910# 全量更新，替换整个jsonPUT /es_text/_doc/1{ &quot;name&quot;: &quot;qyc&quot;, &quot;sex&quot;: 1, &quot;age&quot;: 23,}#查询文档GET /es_text/_doc/1 使用update部分更新，格式: POST /索引名称/update/id update 不会删除原来的文档，而是实现真正的数据更新 12345678910# 部分更新：在原有文档上更新# Update -文档必须已经存在，更新只会对相应字段做增量修改POST /es_text/_update/1{ &quot;doc&quot;:{ &quot;age&quot;: 24 }}GET /es_text/_doc/1 使用 _update_by_query 更新文档 12345678910111213POST /es_text/_update_by_query{ &quot;query&quot;: { &quot;match&quot;: { &quot;_id&quot;: 1 } }, &quot;script&quot;: { &quot;source&quot;: &quot;ctx._source.age = 22&quot; }}GET /es_text/_doc/1 查询文档 根据id查询文档，格式: GET /索引名称/doc/id 1GET /es_text/_doc/1 条件查询 search，格式： /索引名称/doc/_search 12# 查询前10条文档（默认）GET /es_text/_doc/_search ES Search API提供了两种条件查询搜索方式： REST风格的请求URI，直接将参数带过去 （8.x之后不再提供） 封装到request body中，这种方式可以定义更加易读的JSON格式（后面写了） 删除文档 格式: DELETE /索引名称/_doc/id 1DELETE /es_db/_doc/1 ElasticSearch文档批量操作 批量操作可以减少网络连接所产生的开销，提升性能 支持在一次API调用中，对不同的索引进行操作 可以再URI中指定Index，也可以在请求的Payload中进行 操作中单条操作失败，并不会影响其他操作 返回结果包括了每一条操作执行的结果 批量写入 批量对文档进行写操作是通过_bulk的API来实现的 请求方式：POST 请求地址：_bulk 请求参数：通过_bulk操作文档，一般至少有两行参数(或偶数行参数) 第一行参数为指定操作的类型及操作的对象(index,type和id) 第二行参数才是操作的数据 批量创建 12345POST _bulk{&quot;create&quot;:{&quot;_index&quot;:&quot;es_text&quot;,&quot;_id&quot;:4}}{&quot;name&quot;:&quot;xxs&quot;,&quot;sex&quot;:1,&quot;age&quot;:28,&quot;address&quot;:&quot;洛阳科技大厦&quot;}{&quot;create&quot;:{&quot;_index&quot;:&quot;es_text&quot;,&quot;_id&quot;:5}}{&quot;name&quot;:&quot;zmf&quot;,&quot;sex&quot;:1,&quot;age&quot;:29,&quot;address&quot;:&quot;洛阳科技中心大厦&quot;} 批量替换 如果原文档不存在，则是创建 如果原文档存在，则是替换(全量修改原文档) 12345POST _bulk{&quot;index&quot;:{&quot;_index&quot;:&quot;es_text&quot;,&quot;_id&quot;:4}}{&quot;name&quot;:&quot;xxs&quot;,&quot;sex&quot;:1,&quot;age&quot;:28,&quot;address&quot;:&quot;洛阳科技大厦&quot;}{&quot;index&quot;:{&quot;_index&quot;:&quot;es_text&quot;,&quot;_id&quot;:5}}{&quot;name&quot;:&quot;zmf&quot;,&quot;sex&quot;:1,&quot;age&quot;:29,&quot;address&quot;:&quot;洛阳科技中心大厦&quot;} 批量修改 12345POST _bulk{&quot;update&quot;:{&quot;_index&quot;:&quot;es_text&quot;,&quot;_id&quot;:4}}{&quot;doc&quot;:{&quot;name&quot;:&quot;zmf&quot;}}{&quot;update&quot;:{&quot;_index&quot;:&quot;es_text&quot;,&quot;_id&quot;:5}}{&quot;doc&quot;:{&quot;name&quot;:&quot;xxs&quot;}} 批量删除 123POST _bulk{&quot;delete&quot;:{&quot;_index&quot;:&quot;es_text&quot;,&quot;_id&quot;:6}}{&quot;delete&quot;:{&quot;_index&quot;:&quot;es_text&quot;,&quot;_id&quot;:7}} 组合应用 1234POST _bulk{&quot;index&quot;:{&quot;_index&quot;:&quot;es_text&quot;,&quot;_id&quot;:6}}{&quot;name&quot;:&quot;wsq&quot;,&quot;sex&quot;:1,&quot;age&quot;:28,&quot;address&quot;:&quot;洛阳科技大厦&quot;}{&quot;delete&quot;:{&quot;_index&quot;:&quot;es_text&quot;,&quot;_id&quot;:6}} 批量读取 es的批量查询可以使用mget和msearch两种。其中mget是需要我们知道它的id，可以指定不同的 index，也可以指定返回值source。msearch可以通过字段查询来进行一个批量的查找。 1234567891011121314151617181920212223242526272829303132#可以通过ID批量获取不同index和type的数据GET _mget{&quot;docs&quot;: [{&quot;_index&quot;: &quot;es_db&quot;,&quot;_id&quot;: 1},{&quot;_index&quot;: &quot;es_text&quot;,&quot;_id&quot;: 4}]}#可以通过ID批量获取es_db的数据GET /es_text/_mget{&quot;docs&quot;: [{&quot;_id&quot;: 1},{&quot;_id&quot;: 4}]}#简化后GET /es_text/_mget{&quot;ids&quot;:[&quot;1&quot;,&quot;2&quot;]} ES检索原理分析索引的原理索引是加速数据查询的重要手段，其核心原理是通过不断的缩小想要获取数据的范围来筛选出最终想要 的结果，同时把随机的事件变成顺序的事件。 磁盘IO与预读磁盘IO是程序设计中非常高昂的操作，也是影响程序性能的重要因素，因此应当尽量避免过多的磁盘 IO，有效的利用内存可以大大的提升程序的性能。在操作系统层面，发生一次IO时，不光把当前磁盘地 址的数据，而是把相邻的数据也都读取到内存缓冲区内，局部预读性原理告诉我们，当计算机访问一个 地址的数据的时候，与其相邻的数据也会很快被访问到。每一次IO读取的数据我们称之为一页(page)。 具体一页有多大数据跟操作系统有关，一般为4k或8k，也就是我们读取一页内的数据时候，实际上才发 生了一次IO，这个理论对于索引的数据结构设计非常有帮助。 ES倒排索引相当于将存入数据分词器拆分，根据词出现的频率给分，得分进行一个词组排序由高到低 为了进一步提升索引的效率索引结构 相当于将词项索引单词词典（Term Dictionary)[记录所有文档的单词，记录单词到倒排列表的关联关系] 然后根据词典找到倒排列表 (Posting List)[记录了单词对应的文档结合，由倒排索引项组成] 倒排索引项(Posting)： 文档ID 词频TF–该单词在文档中出现的次数，用于相关性评分 位置(Position)-单词在文档中分词的位置。用于短语搜索（match phrase query) 偏移(Offset)-记录单词的开始结束位置，实现高亮显示 ES高级查询Query DSLES中提供了一种强大的检索数据方式,这种检索方式称之为Query DSL（Domain Specified Language） , Query DSL是利用Rest API传递JSON格式的请求体(RequestBody)数据与ES进行交互，这种方式的丰富 查询语法让ES检索变得更强大，更简洁。 主流写法 查询所有 match_all使用match_all，默认只会返回10条数据。原因：_search查询默认采用的是分页查询，每页记录数size的默认值为10。如果想显示更多数据，指定size条数 1234567GET /es_text/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;size&quot;: 100} 分页查询formfrom 关键字: 用来指定起始返回位置，和size关键字连用可实现分页效果 12345678GET /es_db/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;size&quot;: 3, &quot;from&quot;: 0} size不能无限大 默认窗口大小为10000，该窗口大小为from数值与size之和 查询结果窗口可以对index.max_result_window进行设置 设置方法 1234PUT /es_text/_settings{ &quot;index.max_result_window&quot;:&quot;20000&quot;} 但是这样对内存的消耗巨大，引入了分页查询 分页查询Scroll 改动index.max_result_window参数值的大小，只能解决一时的问题，当索引的数据量持续增长时，在 查询全量数据时还是会出现问题。而且会增加ES服务器内存大结果集消耗完的风险。最佳实践还是根据 异常提示中的采用scroll api更高效的请求大量数据集。 123456789#查询命令中新增scroll=1m,说明采用游标查询，保持游标查询窗口一分钟。#这里由于测试数据量不够，所以size值设置为2。#实际使用中为了减少游标查询的次数，可以将值适当增大，比如设置为1000。GET /es_text/_search?scroll=1m{ &quot;query&quot;: { &quot;match_all&quot;: {}}, &quot;size&quot;: 2} 查询结果如图 返回了_scroll_id 的值 可以多次根据scroll_id游标查询，直到没有数据返回则结束查询。采用游标查询索引全量数据，更安全高 效，限制了单次对内存的消耗。 1234567# scroll_id 的值就是上一个请求中返回的 _scroll_id 的值GET /_search/scroll{ &quot;scroll&quot;:&quot;1m&quot;, &quot;scroll_id&quot;: &quot;FGluY2x1ZGVfY29udGV4dF91dWlkDXF1ZXJ5QW5kRmV0Y2gBFklLNUVUcU9qVEpDVExMMVctbGdMWWcAAAAAAAAkBRZUdEllN29zQ1RMR1VIYkd1Q2NsUWJn&quot;} 指定字段排序sort可以根据年龄进行排序 123456789101112131415161718192021222324252627GET /es_text/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;sort&quot;: [ { &quot;age&quot;: &quot;desc&quot; } ]}#排序，分页GET /es_text/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;sort&quot;: [ { &quot;age&quot;: &quot;desc&quot; } ], &quot;from&quot;: 2, &quot;size&quot;: 1} 返回指定字段 _source12345678GET /es_text/_search{ &quot;query&quot;: { &quot;match_all&quot;: {} }, &quot;_source&quot;: [&quot;name&quot;,&quot;address&quot;]} 模糊匹配 matchmatch在匹配时会对所查找的关键词进行分词，然后按分词匹配查找match支持以下参数： query : 指定匹配的值operator : 匹配条件类型and : 条件分词后都要匹配or : 条件分词后有一个匹配即可(默认)minmum_should_match : 最低匹配度，即条件在倒排索引中最低的匹配度 1234567891011121314151617181920212223#模糊匹配 match 分词后or的效果GET /es_text/_search{ &quot;query&quot;: { &quot;match&quot;: { &quot;address&quot;: &quot;洛阳大厦&quot; } }}# 分词后 and的效果GET /es_text/_search{ &quot;query&quot;: { &quot;match&quot;: { &quot;address&quot;: { &quot;query&quot;: &quot;洛阳中心&quot;, &quot;operator&quot;: &quot;AND&quot; } } }} 短语查询 match_phrase1234567891011121314GET /es_text/_search{ &quot;query&quot;: { &quot;multi_match&quot;: { &quot;query&quot;: &quot;qyc洛阳&quot;, &quot;fields&quot;: [ &quot;address&quot;, &quot;name&quot; ] } }}注意：字段类型分词,将查询条件分词之后进行查询，如果该字段不分词就会将查询条件作为整体进行查询。 全字段搜索 query_string12345678910111213141516171819202122232425262728293031#未指定字段查询GET /es_text/_search{ &quot;query&quot;: { &quot;query_string&quot;: { &quot;query&quot;: &quot;xxs OR 洛阳&quot; } }}#指定单个字段查询、#Query StringGET /es_text/_search{ &quot;query&quot;: { &quot;query_string&quot;: { &quot;default_field&quot;: &quot;address&quot;, &quot;query&quot;: &quot;xxs OR 洛阳&quot; } }}#指定多个字段查询GET /es_db/_search{&quot;query&quot;: {&quot;query_string&quot;: {&quot;fields&quot;: [&quot;name&quot;,&quot;address&quot;],&quot;query&quot;: &quot;xxs OR ( 洛阳 AND 大厦)&quot;}}} 关键词查询TermTerm用来使用关键词查询(精确匹配),一般模糊查找的时候，多用 match，而精确查找时可以使用term。 ES中默认使用分词器为标准分词器(StandardAnalyzer),标准分词器对于英文单词分词,对于中文单 字分词。 在ES的Mapping Type 中 keyword , date ,integer, long , double , boolean or ip 这些类型不分 词，只有text类型分词。 12345678910111213141516171819202122232425#关键字查询 termGET /es_text/_search{ &quot;query&quot;:{ &quot;term&quot;: { &quot;address&quot;: { &quot;value&quot;: &quot;中心大厦&quot; } } }}# 采用term精确查询, 查询字段映射类型为keywordGET /es_text/_search{ &quot;query&quot;:{ &quot;term&quot;: { &quot;address.keyword&quot;: { &quot;value&quot;: &quot;中心大厦&quot; } } }}在ES中，Term查询，对输入不做分词。会将输入作为一个整体，在倒排索引中查找准确的词项，并且使用相关度算分公式为每个包含该词项的文档进行相关度算分。 前缀查询 prefix 它不会分析要搜索字符串，传入的前缀就是想要查找的前缀 默认状态下，前缀查询不做相关度分数计算，它只是将所有匹配的文档返回，然后赋予所有相关分数值为1。它的行为更像是一个过滤器而不是查询。两者实际的区别就是过滤器是可以被缓存的，而前缀查询不行。 1234567891011GET /es_text/_search{ &quot;query&quot;: { &quot;prefix&quot;: { &quot;address&quot;: { &quot;value&quot;: &quot;洛阳&quot; } } }} 通配符查询 wildcard1234567891011GET /es_text/_search{ &quot;query&quot;: { &quot;wildcard&quot;: { &quot;address&quot;: { &quot;value&quot;: &quot;*飞*&quot; }· } }} 范围查询 rangerange：范围关键字gte 大于等于lte 小于等于gt 大于lt 小于now 当前时间 1234567891011POST /es_db/_search{ &quot;query&quot;: { &quot;range&quot;: { &quot;age&quot;: { &quot;gte&quot;: 25, &quot;lte&quot;: 28 } } }} 日期 range1234567891011121314151617181920DELETE /productPOST /product/_bulk{&quot;index&quot;:{&quot;_id&quot;:1}}{&quot;price&quot;:100,&quot;date&quot;:&quot;2021-01-01&quot;,&quot;productId&quot;:&quot;XHDK-1293&quot;}{&quot;index&quot;:{&quot;_id&quot;:2}}{&quot;price&quot;:200,&quot;date&quot;:&quot;2022-01-01&quot;,&quot;productId&quot;:&quot;KDKE-5421&quot;}GET /product/_mappingGET /product/_search{ &quot;query&quot;: { &quot;range&quot;: { &quot;date&quot;: { &quot;gte&quot;: &quot;now-2y&quot; } } }} 多 id 查询 ids123456789GET /es_db/_search{ &quot;query&quot;: { &quot;ids&quot;: { &quot;values&quot;: [1,2] } }} 模糊查询 fuzzy在实际的搜索中，我们有时候会打错字，从而导致搜索不到。在Elasticsearch中，我们可以使用fuzziness属性来进行模糊查询，从而达到搜索有错别字的情形。fuzzy 查询会用到两个很重要的参数，fuzziness，prefix_length fuzziness：表示输入的关键字通过几次操作可以转变成为ES库里面的对应field的字段操作是指：新增一个字符，删除一个字符，修改一个字符，每次操作可以记做编辑距离为1，如中文集团到中威集团编辑距离就是1，只需要修改一个字符；该参数默认值为0，即不开启模糊查询。如果fuzziness值在这里设置成2，会把编辑距离为2的东东集团也查出来。prefix_length：表示限制输入关键字和ES对应查询field的内容开头的第n个字符必须完全匹配，不允许错别字匹配如这里等于1，则表示开头的字必须匹配，不匹配则不返回默认值也是0 12345678910111213141516171819202122232425262728GET /es_text/_search{ &quot;query&quot;: { &quot;fuzzy&quot;: { &quot;address&quot;: { &quot;value&quot;: &quot;罗阳&quot;, &quot;fuzziness&quot;: 1 } } }}GET /es_text/_search{ &quot;query&quot;: { &quot;fuzzy&quot;: { &quot;address&quot;: { &quot;value&quot;: &quot;科及&quot;, &quot;fuzziness&quot;: 1 } } }}注意: fuzzy 模糊查询 最大模糊错误 必须在0-2之间- 搜索关键词长度为 2，不允许存在模糊- 搜索关键词长度为3-5，允许1次模糊- 搜索关键词长度大于5，允许最大2次模糊 高亮 highlighthighlight 关键字: 可以让符合条件的文档中的关键词高亮。 pre_tags 前缀标签 post_tags 后缀标签 tags_schema 设置为styled可以使用内置高亮样式 require_field_match 多字段高亮需要设置为false 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687示例代码#指定ik分词器（7.29没有8.3.2版本的需要等待插件更新）PUT /products{ &quot;settings&quot; : { &quot;index&quot; : { &quot;analysis.analyzer.default.type&quot;: &quot;ik_max_word&quot; } }}PUT /products/_doc/1{ &quot;proId&quot; : &quot;2&quot;, &quot;name&quot; : &quot;牛仔男外套&quot;, &quot;desc&quot; : &quot;牛仔外套男装春季衣服男春装夹克修身休闲男生潮牌工装潮流头号青年春秋棒球服男 7705浅蓝常规 XL&quot;, &quot;timestamp&quot; : 1576313264451, &quot;createTime&quot; : &quot;2019-12-13 12:56:56&quot;}PUT /products/_doc/2{ &quot;proId&quot; : &quot;6&quot;, &quot;name&quot; : &quot;HLA海澜之家牛仔裤男&quot;, &quot;desc&quot; : &quot;HLA海澜之家牛仔裤男2019时尚有型舒适HKNAD3E109A 牛仔蓝(A9)175/82A(32)&quot;, &quot;timestamp&quot; : 1576314265571, &quot;createTime&quot; : &quot;2019-12-18 15:56:56&quot;}测试GET /products/_search{ &quot;query&quot;: { &quot;term&quot;: { &quot;name&quot;: { &quot;value&quot;: &quot;牛仔&quot; } } }, &quot;highlight&quot;: { &quot;fields&quot;: { &quot;*&quot;:{} } }}自定义高亮 html 标签可以在 highlight 中使用 pre_tags 和 post_tagsGET /products/_search{ &quot;query&quot;: { &quot;term&quot;: { &quot;name&quot;: { &quot;value&quot;: &quot;牛仔&quot; } } }, &quot;highlight&quot;: { &quot;post_tags&quot;: [&quot;&lt;/span&gt;&quot;], &quot;pre_tags&quot;: [&quot;&lt;span style='color:red'&gt;&quot;], &quot;fields&quot;: { &quot;*&quot;:{} } }}多字段高亮GET /products/_search{ &quot;query&quot;: { &quot;term&quot;: { &quot;name&quot;: { &quot;value&quot;: &quot;牛仔&quot; } } }, &quot;highlight&quot;: { &quot;pre_tags&quot;: [&quot;&lt;font color='red'&gt;&quot;], &quot;post_tags&quot;: [&quot;&lt;font/&gt;&quot;], &quot;require_field_match&quot;: &quot;false&quot;, &quot;fields&quot;: { &quot;name&quot;: {}, &quot;desc&quot;: {} } }} 相关性和相关性算分搜索是用户和搜索引擎的对话，用户关心的是搜索结果的相关性是否可以找到所有相关的内容有多少不相关的内容被返回了文档的打分是否合理结合业务需求，平衡结果排名如何衡量相关性：Precision(查准率)―尽可能返回较少的无关文档Recall(查全率)–尽量返回较多的相关文档Ranking -是否能够按照相关度进行排序 相关性（Relevance）搜索的相关性算分，描述了一个文档和查询语句匹配的程度。ES 会对每个匹配查询条件的结果进行算分_score。打分的本质是排序，需要把最符合用户需求的文档排在前面。ES 5之前，默认的相关性算分采用TF-IDF，现在采用BM 25。 什么是TF-IDFTF-IDF（term frequency–inverse document frequency）是一种用于信息检索与数据挖掘的常用加权技术。 BM25es5之后用的是这个算分 和经典的TF-IDF相比,当TF无限增加时，BM 25算分会趋于一个数值 通过Explain API查看TF-IDF1234567891011121314151617181920PUT /test_score/_bulk{&quot;index&quot;:{&quot;_id&quot;:1}}{&quot;content&quot;:&quot;we use Elasticsearch to power the search&quot;}{&quot;index&quot;:{&quot;_id&quot;:2}}{&quot;content&quot;:&quot;we like elasticsearch&quot;}{&quot;index&quot;:{&quot;_id&quot;:3}}{&quot;content&quot;:&quot;Thre scoring of documents is caculated by the scoring formula&quot;}{&quot;index&quot;:{&quot;_id&quot;:4}}{&quot;content&quot;:&quot;you know,for search&quot;}GET /test_score/_search{ &quot;explain&quot;: true, &quot;query&quot;: { &quot;match&quot;: { &quot;content&quot;: &quot;elasticsearch&quot; } }} BoostingBoosting是控制相关度的一种手段。参数boost的含义： 当boost &gt; 1时，打分的权重相对性提升当0 &lt; boost &lt;1时，打分的权重相对性降低当boost &lt;0时，贡献负分返回匹配positive查询的文档并降低匹配negative查询的文档相似度分。这样就可以在不排除某些文档的前提下对文档进行查询,搜索结果中存在只不过相似度分数相比正常匹配的要低; 12345678910111213141516171819GET /test_score/_search{ &quot;query&quot;: { &quot;boosting&quot;: { &quot;positive&quot;: { &quot;term&quot;: { &quot;content&quot;: &quot;elasticsearch&quot; } }, &quot;negative&quot;: { &quot;term&quot;: { &quot;content&quot;: &quot;like&quot; } }, &quot;negative_boost&quot;: 0.2 } }} 希望包含了某项内容的结果不是不出现，而是排序靠后。 布尔查询bool Query一个bool查询,是一个或者多个查询子句的组合，总共包括4种子句，其中2种会影响算分，2种不影响算分。 must: 相当于&amp;&amp; ，必须匹配，贡献算分should: 相当于|| ，选择性匹配，贡献算分must_not: 相当于! ，必须不能匹配，不贡献算分filter: 必须匹配，不贡献算法在Elasticsearch中，有Query和 Filter两种不同的Context Query Context: 相关性算分Filter Context: 不需要算分 ,可以利用Cache，获得更好的性能相关性并不只是全文本检索的专利，也适用于yes | no 的子句，匹配的子句越多，相关性评分越高。如果多条查询子句被合并为一条复合查询语句，比如 bool查询，则每个查询子句计算得出的评分会被合并到总的相关性评分中。 Boosting QueryBoosting是控制相关的一种手段。可以通过指定字段的boost值影响查询结果 参数boost的含义： 当boost &gt; 1时，打分的权重相对性提升 当0 &lt; boost &lt;1时，打分的权重相对性降低 当boost &lt;0时，贡献负分 1234567891011121314151617181920212223242526272829303132POST /blogs/_bulk{&quot;index&quot;:{&quot;_id&quot;:1}}{&quot;title&quot;:&quot;Apple iPad&quot;,&quot;content&quot;:&quot;Apple iPad,Apple iPad&quot;}{&quot;index&quot;:{&quot;_id&quot;:2}}{&quot;title&quot;:&quot;Apple iPad,Apple iPad&quot;,&quot;content&quot;:&quot;Apple iPad&quot;}GET /blogs/_search{ &quot;query&quot;: { &quot;bool&quot;: { &quot;should&quot;: [ { &quot;match&quot;: { &quot;title&quot;: { &quot;query&quot;: &quot;apple,ipad&quot;, &quot;boost&quot;: 1 } } }, { &quot;match&quot;: { &quot;content&quot;: { &quot;query&quot;: &quot;apple,ipad&quot;, &quot;boost&quot;: 4 } } } ] } }} 利用negative_boost降低相关性negative_boost 对 negative部分query生效计算评分时,boosting部分评分不修改，negative部分query乘以negative_boost值negative_boost取值:0-1.0，举例:0.3对某些返回结果不满意，但又不想排除掉（ must_not)，可以考虑boosting query的negative_boost。 12345678910111213141516171819GET /news/_search{ &quot;query&quot;: { &quot;boosting&quot;: { &quot;positive&quot;: { &quot;match&quot;: { &quot;content&quot;: &quot;apple&quot; } }, &quot;negative&quot;: { &quot;match&quot;: { &quot;content&quot;: &quot;pie&quot; } }, &quot;negative_boost&quot;: 0.2 } }} 常用Mapping参数配置index: 控制当前字段是否被索引，默认为true。如果设置为false，该字段不可被搜索 123456789101112131415161718192021222324252627282930313233DELETE /userPUT /user{&quot;mappings&quot; : { &quot;properties&quot; : { &quot;address&quot; : { &quot;type&quot; : &quot;text&quot;, &quot;index&quot;: false }, &quot;age&quot; : { &quot;type&quot; : &quot;long&quot; }, &quot;name&quot; : { &quot;type&quot; : &quot;text&quot; } }}}PUT /user/_doc/1{&quot;name&quot;:&quot;fox&quot;,&quot;address&quot;:&quot;洛阳洛龙&quot;,&quot;age&quot;:30}GET /userGET /user/_search{&quot;query&quot;: {&quot;match&quot;: {&quot;address&quot;: &quot;洛阳洛龙&quot;}}} 无法找到 Dynamic Template根据Elasticsearch识别的数据类型，结合字段名称，来动态设定字段类型 所有的字符串类型都设定成Keyword，或者关闭keyword 字段 is开头的字段都设置成 boolean long_开头的都设置成 long类型 123456789101112131415161718192021222324252627282930313233PUT /my_test_index{&quot;mappings&quot;: {&quot;dynamic_templates&quot;: [{&quot;full_name&quot;:{&quot;path_match&quot;: &quot;name.*&quot;,&quot;path_unmatch&quot;: &quot;*.middle&quot;,&quot;mapping&quot;:{&quot;type&quot;: &quot;text&quot;,&quot;copy_to&quot;: &quot;full_name&quot;}}}]}}PUT /my_test_index/_doc/1{&quot;name&quot;:{&quot;first&quot;: &quot;John&quot;,&quot;middle&quot;: &quot;Winston&quot;,&quot;last&quot;: &quot;Lennon&quot;}}GET /my_test_index/_search{&quot;query&quot;: {&quot;match&quot;: {&quot;full_name&quot;: &quot;John&quot;}}} 12345678910111213141516171819202122232425PUT /my_index{ &quot;mappings&quot;: { &quot;dynamic_templates&quot;: [ { &quot;strings_as_boolean&quot;: { &quot;match_mapping_type&quot;:&quot;string&quot;, &quot;match&quot;:&quot;is*&quot;, &quot;mapping&quot;: { &quot;type&quot;: &quot;boolean&quot; } } }, { &quot;strings_as_keywords&quot;: { &quot;match_mapping_type&quot;: &quot;string&quot;, &quot;mapping&quot;: { &quot;type&quot;: &quot;keyword&quot; } } } ] }} lndex Template当一个索引被新创建时： 应用Elasticsearch 默认的settings 和mappings 应用order数值低的lndex Template 中的设定 应用order高的 Index Template 中的设定，之前的设定会被覆盖 应用创建索引时，用户所指定的Settings和 Mappings，并覆盖之前模版中的设定","link":"/%E6%95%B0%E6%8D%AE%E5%BA%93/ElasticSearch/ElasticSearch%E5%BC%80%E5%8F%91%E6%89%8B%E5%86%8C/"},{"title":"软件设计师","text":"计算机系统知识 CPU的组成 存储系统 校验码 输入输出 程序设计语言基础知识 后缀式 数据结构与数据运算 树 树转二叉树 图 最小生成树 查找 排序 软件工程基础知识 软件过程模型 软件的四个维护方面 结构化开发方法 结构化分析方法 结构化设计方法 面向对象技术 面向对象测试 UML的关系 设计原则 设计模式 创建型设计模式 结构型设计模式 行为设计模式 算法设计与分析 分治法 动态规划法 贪心法 回溯法 数据库技术基础 关系数据库的规范化 Armstrong公理 数据库操作 关系数据库的规范化 权限 网络与信息安全基础知识 网络体系结构 未分类 关键路径 沟通路径 树的度、叶子节点数、边数 常见协议功能和默认端口 常见算法 可靠度 数据库安全相关术语 软件测试方法 程序流程图 McCabe复杂度 测试 流水线技术 UML序列图 文件系统索引 页式存储管理系统 计算机系统知识CPU的组成CPU主要由运算器、控制器、寄存器组和内部总线等部件组成 运算器 算术逻辑单元(ALU):负责处理数据，实现对数据的算术运算和逻辑运算。 累加寄存器(AC):也称为累加器，是一个通用寄存器，功能是当运算器的算术逻辑单元执行算术运算或逻辑运算时，为ALU提供一个工作区。 数据缓冲寄存器(DR):在对内存储器进行读/写操作时，用DR暂时存放由内存储器读/写的一条指令或一个数据字，将不同时间段内的读/写数据隔离。主要作用是作为CPU和内存、外部设备之间数据传送的中转站;作为CPU和内存、外围设备之间在操作速度上的缓冲;在单累加器结构的运算器中，数据缓冲寄存器还可兼作为操作数据寄存器。 状态条件寄存器(PSW):由算数指令和逻辑指令运行或测试的结果建立的各种条件码内容，主要分为状态标志和控制标志 控制器 指令寄存器（IR）:当CPU执行一条指令时，先把它从内存储器取到缓冲寄存器中，再送入IR暂存，指令译码器根据IR的内容产生各种微操作指令，控制其他的组成部件工作，完成所需的功能。 程序计数器（PC）:存储下一条要执行的指令的地址，具有寄存信息和计数两种功能，又称为指令计数器。程序的执行分为两种情况，一是顺序执行，二是转移执行。 地址寄存器（AR）:保存当前CPU所访问的内存单元的地址。 指令译码器（ID）:指令分为操作码和地址码两个部分，为了执行任何给定的命令，必须对操作码进行分析，以便识别所有完成的操作。 寄存器组寄存器组分为专用寄存器和通用寄存器。运算器和控制器中的寄存器是专用寄存器，其作用是固定的。通用寄存器的用途广泛，并且由程序员规定其用途，其数目因处理器的不同有所差异。 指令寄存器（IR）用来保存当前正在执行的指令。当执行一条指令时，先把它从内存取到数据寄存器（DR）中，然后再传送至IR。为了执行任何给定的指令，必须对操作码进行测试，以便识别所要求的操作，指令译码器（ID）就是做这项工作的。指令寄存器中操作码字段的输出就是指令译码器的输入。操作码一经译码后，即可向操作控制器发出具体操作的特定信号。 地址寄存器（AR）用来保存当前CPU所访问的内存单元的地址。由于内存和CPU之间存在着操作速度上的差别，所以必须使用地址寄存器来保持地址信息，直到内存的读/写操作完成为止。 为了保证程序指令能够连续地执行下去，CPU 必须具有某些手段来确定下一条指令的地址，程序计数器正起到这种作用，所以通常又称为指令计数器。在程序开始执行前，必须将它的起始地址，即程序的一条指令所在的内存单元地址送入程序计数器（PC），因此PC的内容即是从内存提取的第一条指令的地址。当执行指令时，CPU将自动修改PC的内容，即每执行一条指令，PC就增加一个量，这个量等于指令所含的字节数，以便使其总保持将要执行的下一条指令的地址。由于大多数指令都是按顺序来执行的，所以修改的过程通常只是简单地对PC加1。 存储系统 CPU对应的存储类别:寄存器 Cache对应的存储类别:缓存 DRAM对应的存储类别:主存 硬盘、光盘对应的存储类别:辅存 校验码 奇偶校验码 奇偶校验码（Parity Code）是一种简单有效的校验方法。这种方法通过在编码中增加一位校验位，使编码中1的个数为奇数（奇校验）或偶数（偶校验），从而使码距变为2。 海明码 海明码（Hamming Code）是利用奇偶性来查错和纠错的校验方法。 海明码确定校验位公式：$2^k-1 \\geq n+k$$k$：检验位$n$：数据位$n+k$：数据总位数 校验码在二进制串中的位置为2的整数幂。剩下的位置为数据。如下表所示（以1010110这个二进制数为例）： 位置 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011 内容 x1 x2 1 x3 0 1 0 x4 1 1 0 为了求出x2,要使所有位置的第二位是1的数据（即形如*1的位置的数据）的异或值为0（不同为1相同为0，结果就是有偶数个1）。即x2^1^1^0^1^0 = 0。因此x2 = 1。同理可得x1 = 0, x3 = 1, x4 = 0。 位置 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011 内容 0 1 1 1 0 1 0 0 1 1 0 循环冗余校验码 循环冗余校验码（Cyclic Redundancy Check，CRC）由两部分组成，左边为信息码（数据），右边为校验码。 输入输出 程序控制(查询)方式：分为无条件传送和程序查询方式。方法简单，硬件开销小，但IO能力不 高，严重影响CPU的利用率。 程序中断方式：与程序控制方式相比，中断方式因为CPU无需等待而提高了传输请求的响应速度。 DMA方式：DMA方式是为了在主存与外设之间实现高速、批量数据交换而设置的。DMA方式比程序控制方式与中断方式都高效。 程序设计语言基础知识后缀式解决该类问题的方法是将算术表达式构造成一棵二叉树，然后对二叉树进行后序遍历得到后缀式。 a+(b-c)*d的后缀式是abc-d*+ b*(a+c)-d的后缀式是bac+*d- 数据结构与数据运算树 满二叉树：如果一个二叉树的层数为K，结点总数为$2^k-1$个，则它就是满二叉树。 完全二叉树：在一个深度为h的完全二叉树中，除第h层外（最后一层），其他各层都是满的。第h层所有的结点都必须从左到右依次放置，不能留空。 最优二叉树：最优二叉树（哈夫曼树）的求法：给出一组权值，将其中两个最小的权值作为叶子节点，其和作为父节点，组成二叉树，而后删除这两个叶子节点权值，并将父节点的值添加到该组权值中。重复进行上述步骤，直至所有权值都被使用完。哈夫曼树节点的度只能是0度或2度。 树转二叉树 在兄弟结点之间添加连线 去除非长子外的连线 父子连线变为左子树，兄弟连线变为右子树 二叉树转树将上述操作反过来即可 图有向图、无向图以及其邻接矩阵 邻接表：邻接表表示法是指为图中的每一个顶点建立一个单链表。 有向图及其邻接表如下图所示 最小生成树 最小生成树——克鲁斯卡尔算法：这个算法是从边出发的，因为本质是选取权值最小的n-1 条边，因此，就将边按权值大小排序，依次选取权值最小的边，直至囊括所有节点，要注意，每次选边后要检查不能形成环路。克鲁斯卡尔算法的时间复杂度为O（eloge），与图中的顶点数无关，因此该算法适合于求边稀疏的网的最小生成树。 最小生成树——普里姆算法：从任意顶点出发，找出与其邻接的边权值最小的，此时此边的另外一个顶点自动加入树集合中，而后再从这这个树集合的所有顶点中找出与其邻接的边权值最小的，同样此边的另外一个顶点加入树集合中，依次递归，直至图中所有顶点都加入树集合中，此时此树就是该图的最小生成树。普里姆算法的时间复杂度为O（n^2），与图中的边数无关，因此该算法适合于求边稠密的网的最小生成树： 查找 顺序查找将待查的元素从头到尾与表中元素进行比较，如果存在，则返回成功；否则，查找失败。此方法效率不高。顺序查找的平均查找长度为$(n+1)/2$。 二分查找 二分查找的前提是元素有序（一般是升序），基本思路是拿中间元素$A[m]$与要查找的元素$x$进行比较，如果相等，则表示找到；如果$A[m]$比$x$大，那么要找的元素一定在$A[m]$前边（左边）；如果$A[m]$比$x$小，那么要找的元素一定在$A[m]$后边（右边）。每进行一次查找，数组规模减半。反复将子数组规模减半或使当前子数组为空，直到发现要查找的元素。 长度为$n$的有序数组二分查找的最大查找次数为$\\lceil \\log_2 n \\rceil$（向上取整）。 哈希查找 排序详表 排序算法 平均 最好 最坏 空间 排序方式 稳定性 备注 直接插入排序 $O(n^2)$ $O(n)$ $O(n^2)$ $O(1)$ In-place 稳定 左侧已排序，右侧未排序，在插入第$i$个记录时，$R_1$,$R_2$,…,$R_{i-1}$均已排好序，这时将第$i$`个记录依次与$R_{i-1}$,…,$R_2$,$R_1$进行比较，找到合适的位置插入，插入位置及之后的记录依次向后移动 冒泡排序 $O(n^2)$ $O(n)$ $O(n^2)$ $O(1)$ In-place 稳定 通过相邻元素（$i$ 与 $i-1$）之间的比较和交换，将排序码较小的元素逐渐从底层移向顶层。 简单选择排序 $O(n^2)$ $O(n^2)$ $O(n^2)$ $O(1)$ In-place 不稳定 左侧已排序，右侧未排序，在右侧未排序序列中选择一个最小/最大元素与右侧未排序序列中最左边元素交换 希尔排序 $O(n^{1.3})$ $O(n^{1.3})$ $O(n^{1.3})$ $O(1)$ In-place 不稳定 先将整个序列分为若干子列（由某个增量控制），插入排序子列，减少增量，直至减少为1 快速排序 $O(nlog_n)$ $O(nlog_n)$ $O(n^2)$ $O(log_n)$ In-place 不稳定 使用分而治之思想，选中一个基数（base），比它大的放在右，比它小的放在左，分别在递归排序左右两个序列 堆排序 $O(nlog_n)$ $O(nlog_n)$ $O(nlog_n)$ $O(1)$ In-place 不稳定 归并排序 $O(nlog_n)$ $O(nlog_n)$ $O(nlog_n)$ $O(n)$ Out-place 稳定 简图 排序算法的稳定性是指在排序过程中，相等元素的相对顺序是否保持不变。如果一个排序算法在排序后，所有相等元素的相对顺序与排序前相同，那么这个排序算法就是稳定的；否则就是不稳定的。 软件工程基础知识软件过程模型 瀑布模型：只适用于需求明确或者二次开发（需求稳定），当需求不明确时，最终开发的项目会错误，有很大的缺陷。 瀑布模型的优点：容易理解、成本低、强调开发的阶段性早期计划及需求调查和产品测试。 瀑布模型的缺点：缺乏灵活性，客户必须要准确地表达他们的需要；在开始的两个或三个阶段中，很难评估真正的进度状态；项目快结束时，出现大量的集成与测试工作；项目结束之前，不能演示系统的能力。 V模型：强调测试贯穿项目始终，而不是集中在测试阶段。是一种测试的开发模型。是瀑布模型的一个变体。 增量模型：可以有多个可用版本的发布，核心功能往往最先完成，在此基础上，每轮迭代会有新的增量发布， 核心功能可以得到充分测试。强调每一个增量均发布一个可操作的产品。 增量模型的优点：可交付的第一个版本所需要的成本和时间很少，开发由增量表示的小系统所承担的风险不大，由于很快发布了第一个版本，因此可减少用户需求的变更。同时，它也具有瀑布模型所有的优点。 增量模型的缺点：若没有对用户的变更要求进行规划，那么产生的初始增量可能会造成后来增量的不稳定；若需求不像早期思考的那样稳定和完整，那么一些增量就可能需要重新开发或重新发布；管理发生的成本、进度和配置的复杂性可能会超出组织的能力。 演化模型（原型模型、螺旋模型）：典型的演化模型有原型模型和螺旋模型。 原型模型：典型的原型开发方法模型。适用于需求不明确的场景，可以帮助用户明确需求。 螺旋模型：结合了瀑布模型和演化模型的优点，但是增加了风险分析，针对需求不明确的项目，这也是其最大的特点。适合大型项目开发。 喷泉模型：以用户需求为动力，以对象为驱动，适合于面向对象的开发方法 基于构件的开发模型：基于构件的开发模型是指利用预先包装的构件来构造应用系统。构件可以是组织内部开发的构件，也可以是商品化成品（COTS）软件构件。一种基于构件的开发模型包括领域工程和应用系统工程。 形式化方法模型：形式化方法是建立在严格数学基础上的一种软件开发方法，主要活动是生成计算机软件形式化的数学规格说明。 统一过程模型：统一过程（UP）模型是一种“用例和风险驱动，以架构为中心，迭代并增量”的开发过程，由UML方法和工具支持。 统一过程的典型代表是RUP，RUP是UP的商业扩展，完全兼容UP，比UP更完整、更详细。 敏捷方法的总体目标是通过“尽可能早地、持续地对有价值的软件进行交付”使客户满意。敏捷过程的典型方法有很多，每一种方法基于一套原则，这些原则实现了敏捷方法所宣称的理念，即敏捷宣言。 常用的方法：极限编程（XP）、水晶法（Crystal）、并列争球法（Scrum）、自适应软件开发（ASD）、敏捷统一过程（AUP）。 软件的四个维护方面 改正性维护是指改正在系统开发阶段已发生而系统测试阶段尚未发现的错误。 适应性维护是指使应用软件适应信息技术变化和管理需求变化而进行的修改。 完善性维护是指为了扩充功能和改善性能而进行的修改，主要是指对已有的软件系统增加一些在系统分析和设计阶段中没有规定的功能与性能特征。 预防性维护是指为了改进应用软件的可靠性和可维护性，为了适应未来的软件、硬件环境的变化，应主动增加预防性的新功能，以使应用系统可以适应各类变化而不被淘汰。 结构化开发方法结构化分析方法结构化分析（SA）概述抽象（自底向上）、分解（自顶向下） 数据流图（DFD）的基本要素：外部实体、加工、数据存储、数据流 数据流图的常见错误 数据流图的审查 一致性：父图与子图平衡、数据守恒、具备数据存储、输出不能与输入同名。 完整性：奇迹（无入有出）、黑洞（有入无出）、灰洞（无法出）。 结构化设计方法 模块结构图是结构化设计的工具，由模块、调用、数据、控制和转接五种基本符号组成。 结构化设计主要包括：体系结构设计、数据设计、接口设计、过程设计。 面向对象技术面向对象测试面向对象测试分为四个层次执行: 算法层:测试类中定义的每个方法，基本相当于传统软件测试的单元测试。 类层:测试封装在同一个类中的所有方法与属性之间的相互作用。可以认为是面向对象测试中特有的模块测试。 模板层:测试一组协调工作的类之间的相互作用。大体上相当于传统软件测试中的集成测试。 系统层:把各个子系统组装成完整的面向对象软件系统，在组装过程中同时进行测试。 UML的关系UML中有四种关系：依赖、关联、泛化和实现 依赖关系：一个事物发生变化影响另一个事物。 关联关系：描述了一组链，链是对象之间的连接。 泛化关系：特殊/一般关系。 实现关系：接口与类之间的关系。 聚合关系：整体与部分生命周期不同。 组合关系：整体与部分生命周期相同。 设计原则 稳定抽象原则:此原则强调的是包的抽象程度与其稳定程度一致。 稳定依赖原则:此原则要求包之间的依赖关系都应该是稳定方向依赖的，即包要依赖的包要比自己更具有稳定性。 依赖倒置原则:此原则强调的是程序应该依赖于抽象接口，而不是具体的实现，从而降低客户与实现模块间的耦合。 无环依赖:这个原则明确指出，在组件的依赖关系在图中不允许存在环。 设计模式创建型设计模式 抽象工厂（Abstract Factory）提供一个接口，用于创建相关或依赖对象的家族，而无需明确指定具体类。应用场景：需要创建一组相关或相互依赖的对象时，例如跨平台 UI 工具包。 生成器（Builder）将一个复杂对象的构建过程与其表示分离，使得同样的构建过程可以创建不同的表示。应用场景：需要创建复杂对象，并且需要灵活地控制其构建过程时，例如构建器模式用于生成复杂的文档或报表。 工厂方法（Factory Method）定义一个用于创建对象的接口，让子类决定实例化哪一个类。应用场景：当一个类无法预知它需要创建的对象时，例如日志记录器可以根据配置选择不同的日志记录方式。 原型（Prototype）通过复制现有对象来创建新对象，而不是通过实例化类。应用场景：需要大量相似对象时，例如克隆复杂对象以提高性能。 单例（Singleton）确保一个类只有一个实例，并提供一个全局访问点。应用场景：需要全局唯一的对象时，例如配置管理器、线程池或数据库连接池。 结构型设计模式 适配器（Adapter）将一个类的接口转换成客户希望的另一个接口，使得原本由于接口不兼容而不能一起工作的类可以协同工作。应用场景：系统需要使用现有的类，但其接口不符合需求时，例如将旧系统的接口适配到新系统。 桥接（Bridge）将抽象部分与实现部分分离，使它们可以独立变化。应用场景：需要在抽象和实现之间增加更多的灵活性时，例如跨平台图形界面工具。 组合（Composite）将对象组合成树形结构以表示“部分-整体”的层次结构，使得客户端可以统一地处理单个对象和组合对象。应用场景：需要表示对象的部分-整体层次结构时，例如文件系统中的文件和文件夹。 装饰（Decorator）动态地给对象添加一些额外的职责，而不影响其他对象的功能。应用场景：需要动态地扩展对象的功能时，例如为图形界面组件添加滚动条或边框。 外观（Facade）为子系统中的一组接口提供一个一致的界面，使得子系统更容易使用。应用场景：需要为复杂的子系统提供一个简单的接口时，例如为多模块系统提供统一的入口。 享元（Flyweight）运用共享技术有效地支持大量细粒度对象的复用，减少内存消耗。应用场景：需要大量相似对象时，例如字符处理系统中的字符对象。 代理（Proxy）为其他对象提供一种代理以控制对这个对象的访问。应用场景：需要控制对对象的访问时，例如远程代理、虚拟代理或保护代理。 行为设计模式 责任链（Chain of Responsibility）允许多个对象有机会处理请求，将这些对象连成一条链，沿着链传递请求，直到某个对象处理它为止。应用场景：日志处理、权限校验等。 命令（Command）将请求封装为对象，使得可以用不同的请求、队列或日志来参数化对象。支持撤销和重做操作。应用场景：事务操作、按钮点击事件处理。 解释器（Interpreter）定义一种语言的文法表示，并提供一个解释器来解释语言中的句子。应用场景：编译器、正则表达式解析器。 迭代器（Iterator）提供一种方法顺序访问集合对象中的元素，而不暴露其内部表示。应用场景：遍历集合（如数组、链表）。 中介者（Mediator）用一个中介对象封装一组对象之间的交互，使对象之间不需要直接引用，降低耦合性。应用场景：聊天室、MVC 中的控制器。 备忘录（Memento）在不破坏封装的前提下，捕获对象的内部状态，并在以后恢复它。应用场景：撤销功能、游戏存档。 观察者（Observer）定义对象间的一对多依赖关系，当一个对象状态改变时，所有依赖它的对象都会收到通知并自动更新。应用场景：事件监听、发布-订阅模式。 状态（State）允许对象在内部状态改变时改变其行为，看起来像是改变了其类。应用场景：状态机、订单状态管理。 策略（Strategy）定义一系列算法，将每个算法封装起来，并使它们可以互换。应用场景：支付方式选择、排序算法。 模板方法（Template Method）定义一个操作的骨架，将一些步骤延迟到子类中。子类可以不改变骨架的情况下重新定义某些步骤。应用场景：算法框架、代码生成器。 访问者（Visitor）提供一种操作一组对象的方法，使得可以在不改变这些对象的类的前提下定义新的操作。应用场景：编译器语法树操作、对象结构遍历。 算法设计与分析分治法基本思想 使用递归技术，把一个问题拆分成多个小规模的相同子问题。 实例：归并排序、快速排序、二分搜索 动态规划法基本思想 找出最优解的性质，并刻画其结构特征。 递归定义最优解的值。 自底向上算出最优解。 构造最优解。 实例：矩阵乘法、背包问题、LCS最长公共子序列 贪心法一般用于求满意解，特殊情况可求最优解(部分背包) 实例：背包问题(如装箱)、多机调度、找零钱问题 回溯法系统地搜索一个问题的所有解或任一解。有试探和回退的过程。 实例：N皇后问题、迷宫、背包 问题 数据库技术基础关系数据库的规范化Armstrong公理Armstrong公理系统设关系模式R&lt;U,F&gt;，其中U为属性集，F是U上的一组函数依赖，那么有如下推理规则： A1自反律：若Y⊆X⊆U，则X→Y为F所蕴含；A2增广律：若X→Y为F所蕴含，且Z⊆U，则XZ→YZ为F所蕴含；A3传递律：若X→Y，Y→Z为F所蕴含，则X→Z为F所蕴含。 根据上面三条推理规则，又可推出下面三条推理规则： 合并规则：若X→Y，X→Z，则X→YZ为F所蕴含。分解规则：若X→Y，Z⊆Y，则X→Z为F所蕴含。伪传递规则：若X→Y，WY→Z，则XW→Z为F所蕴含。 数据库操作基本关系运算 笛卡尔积：相乘。 投影π：选列。 选择σ：选行。 自然连接~：结果的属性列数是二者之和减去重复列数，结果元组是同名属性列取值相等的元组。 关系数据库的规范化 1NF：属性值都是不可分的原子值。 2NF：在1NF基础上，消除了非主属性对候选键的部分函数依赖。 3NF：在2NF基础上，消除了非主属性对候选键的传递函数依赖。 4NF：消除了多值依赖的问题。 权限 GRANT：授权 REVOKE：撤权 网络与信息安全基础知识网络体系结构 层次 名称 主要功能 主要设备及协议 7 应用层 实现具体的应用功能 POP3、FTP、HTTP、Telnet、SMTP、DHCP、TFTP、SNMP、DNS 6 表示层 数据的格式与表达、加密、压缩 同应用层 ↑ 5 会话层 建立、管理和终止会话 同应用层 ↑ 4 传输层 端到端的连接（端口） TCP、UDP 3 网络层 分组传输和路由选择（IP） 三层交换机、路由器、ARP、RARP、IP、ICMP、IGMP 2 数据链路层 传送以帧为单位的信息（MAC） 网桥、交换机、网卡、PPPT、L2TP、SLIP、PPP 1 物理层 二进制传输（01） 中继器、集线器 未分类关键路径项目软件活动图中，关键路径指的是从开始到结束最长的一条路径 沟通路径$$C=n(n-1)/2$$ n：团队成员数量C：沟通路径条数 树的度、叶子节点数、边数问：对于一棵树，每个结点的孩子个数称为结点的度，结点度数的最大值成为树的度。某树T的度为4，其中有5个度为4的结点，8个度为3的结点，6个度为2的结点，10个度为1的结点，则T中的叶子结点个数为? 解：设度为0的叶子结点数为$n_0$,度为1的结点数为$n_1$，度为2的结点数为$n_2$，度为3的结点数是$n_3$，度为4的结点数为$n_4$ $n_1=10$ $n_2=6$ $n_3=8$ $n_4=5$ 这里有一个公式 $边的总数=结点总数-1$ 度数为n的节点会向下产生n条边，那么就有 $4n_4+3n_3+2n_2+n_1=n_0+n_1+n_2+n_3+n_4-1$ $20+24+12+10=n_0+29-1$ $n_0=38$ 因此叶子结点个数为38 常见协议功能和默认端口 协议名 默认端口 功能 特殊说明 HTTP 80 超文本传输协议，网页传输 不安全，结合SSL的HTTPS协议是安全的超文本传输协议，默认端口443 Telnet 23 远程协议 不安全，SSH是安全的远程协议 FTP 20数据 21控制 文件传输协议 不安全，结合SSL的SFTP是安全的文件传输协议。 POP3 110 邮件收取 附加多媒体数据时需采用MIME（MIME不安全，结合SSL的MIME/S是安全的多媒体邮件协议）。使用WEB方式收发电子邮件时必须设置账号密码登录。 SMTP 25 邮件发送 DNS 53 域名解析协议，记录域名与IP的映射关系 本地客户端主机首查本机hosts文件 域名服务器首查本地缓存 DHCP 67 IP 地址自动分配 169.254.X.X 和 0.0.0.0 是无效地址 SNMP 161 简单网络管理协议 服务器仅发送消息给当前团体 ARP 地址解析协议，IP 地址转换为 MAC 地址 ARP Request 请求采用广播进行传送 ARP Response 响应采用单播进行传送 RARP 反向地址解析协议，MAC 地址转 IP 地址 无 ICMP 因特网控制协议 PING 命令来自该协议 IGMP 组播协议 无 常见算法 Hash算法 SHA 对称加密算法 DES IDEA 非对称加密算法 RSA 可靠度 串联的可靠度位每个部件相乘 并联的可靠度为$(1-(1-R)^n)$其中$(1-R)$为单个组件的不可靠度，并联的总体不可靠度为单个组件的不可靠度的乘积$(1-R)^n$，因此总体的可靠度为$(1-(1-R)^n)$ 数据库安全相关术语 拖库: 本是数据库领域的专用术语，指从数据库中导出数据。现指网站遭到入侵后，黑客窃取数据库的行为，即数据库信息泄露。 撞库: 使用大量从一个网站获取的账号密码，尝试登录另一个网站。基于用户密码复用率较高的问题，利用泄露的密码尝试其他网站。 洗库: 黑客入侵网站后获取大量用户数据，通过技术手段和黑色产业链将有价值的数据变现。 社工库: 黑客将获取的各种数据库关联起来，对用户进行全方位画像。 软件测试方法 语句覆盖：每个语句至少执行一次（进每个房间）。 分支覆盖：每个条件的每个分支至少执行一次（开关每扇门）。 判定覆盖：每个条件的每个布尔值（True/False）至少执行一次（测试灯的开关）。 路径覆盖：每条可能的路径至少执行一次（探索迷宫中的每条路径）。 程序流程图McCabe复杂度 语句覆盖(Sstatement Coverage):也称为行覆盖，它关注的是程序中每一行代码是否至少被执行一次。这是最基本的测试爱盖标准，但往往只能发现简单的错误。 判定覆盖(Decision Coverage):也称为分支覆盖，它要求程序中的每一个判定(例if-else语句)的每一种可能古果(真或假)都至少发生一次。这比语句夏盖更全面，但可能会逮漏一些错误。 条件硬盖(Condtioncoverage):它要求程序中的每一个条件(例如语句中的条件)的每一种可能结果(真或假)都至少发生一次。虽然这比判定要盖更全面，但它仍然可能患漏一些错误，因为它不保证所有条件的组合都被测试到。 路径硬盖(Patn Coverage):它要求测试瘦盖程序中所有可能的执行路径。这通常意味着测试需要遍历程序中所有可能的条件组合。路经覆善是这些法项中最全面的测试覆盖方法，因为它考虑了程序中所有可能的执行路径。 测试 语句覆盖：2路径覆盖：4 路径覆盖：6 流水线技术 流水线建立时间：第1条指令执行时间。 流水线周期：指令分段后，最长段时间。 流水线执行时间：流水线总+(指令条数- 1)*流水线周期。 吞吐率=指令条数/流水线执行时间。 最大吞吐率=流水线周期的倒数。 UML序列图loop循环 文件系统索引 第一问：地址直接访问和一级间接地址访问 第二问解答： $1kb/4b=256$ 直接索引地址：$5*(256^0)=5$一级间接地址索引：$2*(256^1)=512$二级间接地址索引：$1*(256^2)=2^{16}$$5+512+2^{16}=66053$ 第二问答案：66053 页式存储管理系统 0对应的是2$2*4k=8k=8192$ 逻辑地址8644对应的页号是2(8644/4k,取2余452)因此位于第2页452处，也就是第8块452处$8*4k+452=33220$因此答案是33220","link":"/%E8%BD%AF%E8%80%83/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%E5%B8%88/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%E5%B8%88/"}],"tags":[{"name":"C&#x2F;C++","slug":"C-C","link":"/tags/C-C/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"kubernetes","slug":"kubernetes","link":"/tags/kubernetes/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"运维","slug":"运维","link":"/tags/%E8%BF%90%E7%BB%B4/"},{"name":"问题解决","slug":"问题解决","link":"/tags/%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"},{"name":"hexo","slug":"hexo","link":"/tags/hexo/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"PostgreSQL","slug":"PostgreSQL","link":"/tags/PostgreSQL/"},{"name":"数据库","slug":"数据库","link":"/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"软考","slug":"软考","link":"/tags/%E8%BD%AF%E8%80%83/"},{"name":"软件设计师","slug":"软件设计师","link":"/tags/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%E5%B8%88/"},{"name":"ElasticSearch","slug":"ElasticSearch","link":"/tags/ElasticSearch/"}],"categories":[{"name":"C&#x2F;C++","slug":"C-C","link":"/categories/C-C/"},{"name":"Docker","slug":"Docker","link":"/categories/Docker/"},{"name":"kubernetes","slug":"kubernetes","link":"/categories/kubernetes/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"hexo","slug":"hexo","link":"/categories/hexo/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"软考","slug":"软考","link":"/categories/%E8%BD%AF%E8%80%83/"},{"name":"PostgreSQL","slug":"数据库/PostgreSQL","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/PostgreSQL/"},{"name":"软件设计师","slug":"软考/软件设计师","link":"/categories/%E8%BD%AF%E8%80%83/%E8%BD%AF%E4%BB%B6%E8%AE%BE%E8%AE%A1%E5%B8%88/"},{"name":"ElasticSearch","slug":"数据库/ElasticSearch","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/ElasticSearch/"}],"pages":[]}